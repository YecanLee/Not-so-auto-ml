{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>District</th>\n",
       "      <th>Block</th>\n",
       "      <th>CultLand</th>\n",
       "      <th>CropCultLand</th>\n",
       "      <th>LandPreparationMethod</th>\n",
       "      <th>CropTillageDate</th>\n",
       "      <th>CropTillageDepth</th>\n",
       "      <th>CropEstMethod</th>\n",
       "      <th>RcNursEstDate</th>\n",
       "      <th>...</th>\n",
       "      <th>Harv_method</th>\n",
       "      <th>Harv_date</th>\n",
       "      <th>Harv_hand_rent</th>\n",
       "      <th>Threshing_date</th>\n",
       "      <th>Threshing_method</th>\n",
       "      <th>Residue_length</th>\n",
       "      <th>Residue_perc</th>\n",
       "      <th>Stubble_use</th>\n",
       "      <th>Acre</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>ID_1J0W3DPCM4H8</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>Mahua</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>TractorPlough FourWheelTracRotavator</td>\n",
       "      <td>2022-06-25</td>\n",
       "      <td>4</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>800.0</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>machine</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>ID_2AYN21MOHJ0T</td>\n",
       "      <td>Nalanda</td>\n",
       "      <td>Rajgir</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>TractorPlough FourWheelTracRotavator</td>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>6</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>machine</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>ID_162UEZJWF00U</td>\n",
       "      <td>Nalanda</td>\n",
       "      <td>Rajgir</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>WetTillagePuddling TractorPlough FourWheelTrac...</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>6</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>machine</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>ID_8GSCZYF1YH2G</td>\n",
       "      <td>Nalanda</td>\n",
       "      <td>Rajgir</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>TractorPlough</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>4</td>\n",
       "      <td>LineSowingAfterTillage</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>...</td>\n",
       "      <td>machine</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>machine</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>ID_1635AF76YBGK</td>\n",
       "      <td>Nalanda</td>\n",
       "      <td>Rajgir</td>\n",
       "      <td>200</td>\n",
       "      <td>195</td>\n",
       "      <td>WetTillagePuddling TractorPlough FourWheelTrac...</td>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>3</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>...</td>\n",
       "      <td>machine</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>machine</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>ID_2FVBQXXYV589</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>Garoul</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>FourWheelTracRotavator</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>6</td>\n",
       "      <td>LineSowingAfterTillage</td>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>hand</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>ID_12X5MHEUNXX4</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>Mahua</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TractorPlough</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>4</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>hand</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>ID_AOJWELMK62ZR</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>Mahua</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>TractorPlough FourWheelTracRotavator</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>5</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-10-15</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>hand</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>ID_Z5DM6T0SOBZC</td>\n",
       "      <td>Jamui</td>\n",
       "      <td>Jamui</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>TractorPlough</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>4</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>machine</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>ID_NF99Y3VUGV1E</td>\n",
       "      <td>Jamui</td>\n",
       "      <td>Jamui</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>TractorPlough BullockPlough</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>4</td>\n",
       "      <td>Manual_PuddledRandom</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>hand</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>hand</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>plowed_in_soil</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  District   Block  CultLand  CropCultLand  \\\n",
       "2587  ID_1J0W3DPCM4H8  Vaishali   Mahua        20            12   \n",
       "2740  ID_2AYN21MOHJ0T   Nalanda  Rajgir        32            30   \n",
       "1961  ID_162UEZJWF00U   Nalanda  Rajgir        55            50   \n",
       "2516  ID_8GSCZYF1YH2G   Nalanda  Rajgir        70            70   \n",
       "2382  ID_1635AF76YBGK   Nalanda  Rajgir       200           195   \n",
       "765   ID_2FVBQXXYV589  Vaishali  Garoul        16            16   \n",
       "2806  ID_12X5MHEUNXX4  Vaishali   Mahua         1             1   \n",
       "1316  ID_AOJWELMK62ZR  Vaishali   Mahua        12             8   \n",
       "2307  ID_Z5DM6T0SOBZC     Jamui   Jamui        14            14   \n",
       "219   ID_NF99Y3VUGV1E     Jamui   Jamui        30            30   \n",
       "\n",
       "                                  LandPreparationMethod CropTillageDate  \\\n",
       "2587               TractorPlough FourWheelTracRotavator      2022-06-25   \n",
       "2740               TractorPlough FourWheelTracRotavator      2022-07-10   \n",
       "1961  WetTillagePuddling TractorPlough FourWheelTrac...      2022-07-15   \n",
       "2516                                      TractorPlough      2022-06-26   \n",
       "2382  WetTillagePuddling TractorPlough FourWheelTrac...      2022-07-12   \n",
       "765                              FourWheelTracRotavator      2022-07-13   \n",
       "2806                                      TractorPlough      2022-06-22   \n",
       "1316               TractorPlough FourWheelTracRotavator      2022-06-09   \n",
       "2307                                      TractorPlough      2022-08-06   \n",
       "219                         TractorPlough BullockPlough      2022-07-20   \n",
       "\n",
       "      CropTillageDepth           CropEstMethod RcNursEstDate  ... Harv_method  \\\n",
       "2587                 4    Manual_PuddledRandom    2022-06-02  ...        hand   \n",
       "2740                 6    Manual_PuddledRandom    2022-06-18  ...        hand   \n",
       "1961                 6    Manual_PuddledRandom    2022-06-26  ...        hand   \n",
       "2516                 4  LineSowingAfterTillage    2022-06-30  ...     machine   \n",
       "2382                 3    Manual_PuddledRandom    2022-06-15  ...     machine   \n",
       "765                  6  LineSowingAfterTillage    2022-06-05  ...        hand   \n",
       "2806                 4    Manual_PuddledRandom    2022-07-01  ...        hand   \n",
       "1316                 5    Manual_PuddledRandom    2022-06-14  ...        hand   \n",
       "2307                 4    Manual_PuddledRandom    2022-07-16  ...        hand   \n",
       "219                  4    Manual_PuddledRandom    2022-06-18  ...        hand   \n",
       "\n",
       "       Harv_date Harv_hand_rent Threshing_date  Threshing_method  \\\n",
       "2587  2022-11-04          800.0     2022-11-19           machine   \n",
       "2740  2022-11-25          400.0     2023-02-23           machine   \n",
       "1961  2022-12-15         1500.0     2023-01-20           machine   \n",
       "2516  2022-12-02            NaN     2022-12-05           machine   \n",
       "2382  2022-11-15            NaN     2022-11-15           machine   \n",
       "765   2022-10-12         1500.0     2022-10-20              hand   \n",
       "2806  2022-11-01          200.0     2022-11-11              hand   \n",
       "1316  2022-10-15          600.0     2022-10-27              hand   \n",
       "2307  2022-11-17          500.0     2023-01-18           machine   \n",
       "219   2022-11-28           90.0     2023-02-13              hand   \n",
       "\n",
       "     Residue_length Residue_perc     Stubble_use      Acre Yield  \n",
       "2587             30           10  plowed_in_soil  0.181818   280  \n",
       "2740             25           10  plowed_in_soil  0.187500   450  \n",
       "1961             24           10  plowed_in_soil  0.718750  1800  \n",
       "2516             28           40  plowed_in_soil  0.312500   560  \n",
       "2382             30           40  plowed_in_soil  0.625000  1250  \n",
       "765              19           10  plowed_in_soil  0.727273  1120  \n",
       "2806             30           10  plowed_in_soil  0.045455    70  \n",
       "1316             30           10  plowed_in_soil  0.136364     6  \n",
       "2307             28           10  plowed_in_soil  0.227273   400  \n",
       "219              29           10  plowed_in_soil  0.454545   800  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_new.csv')\n",
    "train_data, valid_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data = TabularDataset(train_data)\n",
    "valid_data = TabularDataset(valid_data)\n",
    "# subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.core.dataset.TabularDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Test data without label.\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    2476.000000\n",
      "mean      568.142165\n",
      "std       442.049203\n",
      "min         4.000000\n",
      "25%       300.000000\n",
      "50%       430.000000\n",
      "75%       729.750000\n",
      "max      4050.000000\n",
      "Name: Yield, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'Yield'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean root sqaured error is not part of the implemented metrics inside the AutoGluon    \n",
    "Thus we need to implement this method by ourselves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.sqaure(y_true - y_pred))) \n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try with different metrics, remeber to change the metric parameter into different value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240303_155004\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240303_155004/ds_sub_fit/sub_fit_ho.\n",
      "2024-03-03 16:50:04,593\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240303_155004/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.0\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #21~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Feb  9 13:32:52 UTC 2\n",
      "CPU Count:          32\n",
      "Memory Avail:       60.00 GB / 62.71 GB (95.7%)\n",
      "Disk Space Avail:   270.35 GB / 456.89 GB (59.2%)\n",
      "===================================================\n",
      "Train Data Rows:    2200\n",
      "Train Data Columns: 43\n",
      "Label Column:       Yield\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    61441.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.64 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['NursDetFactor', 'TransDetFactor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 53\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 2): ['ID', 'Residue_perc']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', [])    : 1 | ['Residue_perc']\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 14 | ['SeedlingsPerPit', 'TransplantingIrrigationHours', 'TransIrriCost', 'StandingWater', 'Ganaura', ...]\n",
      "\t\t('int', [])                        :  5 | ['CultLand', 'CropCultLand', 'CropTillageDepth', 'NoFertilizerAppln', 'Residue_length']\n",
      "\t\t('object', [])                     : 15 | ['District', 'Block', 'LandPreparationMethod', 'CropEstMethod', 'TransplantingIrrigationSource', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  5 | ['CropTillageDate', 'RcNursEstDate', 'SeedingSowingTransplanting', 'Harv_date', 'Threshing_date']\n",
      "\t\t('object', ['text'])               :  2 | ['NursDetFactor', 'TransDetFactor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 12 | ['District', 'Block', 'LandPreparationMethod', 'CropEstMethod', 'TransplantingIrrigationSource', ...]\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['NursDetFactor', 'TransDetFactor']\n",
      "\t\t('float', [])                       : 14 | ['SeedlingsPerPit', 'TransplantingIrrigationHours', 'TransIrriCost', 'StandingWater', 'Ganaura', ...]\n",
      "\t\t('int', [])                         :  5 | ['CultLand', 'CropCultLand', 'CropTillageDepth', 'NoFertilizerAppln', 'Residue_length']\n",
      "\t\t('int', ['binned', 'text_special']) : 12 | ['NursDetFactor.char_count', 'NursDetFactor.word_count', 'NursDetFactor.capital_ratio', 'NursDetFactor.lower_ratio', 'NursDetFactor.symbol_count. ', ...]\n",
      "\t\t('int', ['bool'])                   :  3 | ['Harv_method', 'Threshing_method', 'Stubble_use']\n",
      "\t\t('int', ['datetime_as_int'])        : 22 | ['CropTillageDate', 'CropTillageDate.month', 'CropTillageDate.day', 'CropTillageDate.dayofweek', 'RcNursEstDate', ...]\n",
      "\t\t('int', ['text_ngram'])             : 54 | ['__nlp__.calendardate', '__nlp__.calendardate irrigwateravailability', '__nlp__.calendardate irrigwateravailability labouravailability', '__nlp__.calendardate irrigwateravailability seedavailability', '__nlp__.calendardate labouravailability', ...]\n",
      "\t0.8s = Fit runtime\n",
      "\t41 features in original data used to generate 124 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.82s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_epochs': 20},\n",
      "\t'GBM': {'num_boost_round': 40},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 2 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 599.3s of the 899.18s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tunhashable type: 'list'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 692, in _calculate_total_resources\n",
      "    minimum_model_resources = self.get_minimum_resources(is_gpu_available=(num_gpus > 0))\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1262, in get_minimum_resources\n",
      "    return self._get_model_base().get_minimum_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 391, in get_minimum_resources\n",
      "    if is_gpu_available and self._is_gpu_lgbm_installed():\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 374, in _is_gpu_lgbm_installed\n",
      "    try_import_lightgbm()\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/compat.py\", line 147, in <module>\n",
      "    from dask.distributed import Client, Future, default_client, wait\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/dask/distributed.py\", line 13, in <module>\n",
      "    from distributed import *\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/__init__.py\", line 23, in <module>\n",
      "    from distributed.actor import Actor, ActorFuture, BaseActorFuture\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/actor.py\", line 13, in <module>\n",
      "    from distributed.client import Future\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/client.py\", line 118, in <module>\n",
      "    from distributed.worker import get_client, get_worker, secede\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker.py\", line 120, in <module>\n",
      "    from distributed.worker_memory import (\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker_memory.py\", line 56, in <module>\n",
      "    WorkerDataParameter: TypeAlias = Union[\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 243, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 316, in __getitem__\n",
      "    return self._getitem(self, parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 421, in Union\n",
      "    parameters = _remove_dups_flatten(parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 215, in _remove_dups_flatten\n",
      "    all_params = set(params)\n",
      "TypeError: unhashable type: 'list'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 598.83s of the 898.7s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.01%)\n",
      "\t-165.5483\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.28s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 874.23s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t-165.5483\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 2 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 874.19s of the 874.18s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tunhashable type: 'list'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 692, in _calculate_total_resources\n",
      "    minimum_model_resources = self.get_minimum_resources(is_gpu_available=(num_gpus > 0))\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1262, in get_minimum_resources\n",
      "    return self._get_model_base().get_minimum_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 391, in get_minimum_resources\n",
      "    if is_gpu_available and self._is_gpu_lgbm_installed():\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 374, in _is_gpu_lgbm_installed\n",
      "    try_import_lightgbm()\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/compat.py\", line 147, in <module>\n",
      "    from dask.distributed import Client, Future, default_client, wait\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/dask/distributed.py\", line 13, in <module>\n",
      "    from distributed import *\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/__init__.py\", line 23, in <module>\n",
      "    from distributed.actor import Actor, ActorFuture, BaseActorFuture\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/actor.py\", line 13, in <module>\n",
      "    from distributed.client import Future\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/client.py\", line 118, in <module>\n",
      "    from distributed.worker import get_client, get_worker, secede\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker.py\", line 120, in <module>\n",
      "    from distributed.worker_memory import (\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker_memory.py\", line 56, in <module>\n",
      "    WorkerDataParameter: TypeAlias = Union[\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 243, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 316, in __getitem__\n",
      "    return self._getitem(self, parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 421, in Union\n",
      "    parameters = _remove_dups_flatten(parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 215, in _remove_dups_flatten\n",
      "    all_params = set(params)\n",
      "TypeError: unhashable type: 'list'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 874.06s of the 874.05s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.01%)\n",
      "\t-162.2311\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.51s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 852.31s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L2': 0.603, 'NeuralNetTorch_BAG_L1': 0.397}\n",
      "\t-159.6431\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 47.78s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240303_155004/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                   model  holdout_score   score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L3    -160.463909 -159.643092  root_mean_squared_error        2.050105       0.196894  40.836426                 0.000989                0.000259           0.043511            3       True          4\n",
      "1  NeuralNetTorch_BAG_L2    -160.962191 -162.231123  root_mean_squared_error        2.049116       0.196635  40.792915                 0.093752                0.099261          20.508381            2       True          3\n",
      "2  NeuralNetTorch_BAG_L1    -161.290628 -165.548320  root_mean_squared_error        1.955363       0.097374  20.284534                 1.955363                0.097374          20.284534            1       True          1\n",
      "3    WeightedEnsemble_L2    -161.290628 -165.548320  root_mean_squared_error        1.956329       0.097647  20.288447                 0.000966                0.000273           0.003912            2       True          2\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 50 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 3550 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 3550s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240303_155004\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.0\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #21~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Feb  9 13:32:52 UTC 2\n",
      "CPU Count:          32\n",
      "Memory Avail:       56.13 GB / 62.71 GB (89.5%)\n",
      "Disk Space Avail:   270.34 GB / 456.89 GB (59.2%)\n",
      "===================================================\n",
      "Train Data Rows:    2476\n",
      "Train Data Columns: 43\n",
      "Label Column:       Yield\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    57485.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['NursDetFactor', 'TransDetFactor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 55\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 2): ['ID', 'Residue_perc']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', [])    : 1 | ['Residue_perc']\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 14 | ['SeedlingsPerPit', 'TransplantingIrrigationHours', 'TransIrriCost', 'StandingWater', 'Ganaura', ...]\n",
      "\t\t('int', [])                        :  5 | ['CultLand', 'CropCultLand', 'CropTillageDepth', 'NoFertilizerAppln', 'Residue_length']\n",
      "\t\t('object', [])                     : 15 | ['District', 'Block', 'LandPreparationMethod', 'CropEstMethod', 'TransplantingIrrigationSource', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  5 | ['CropTillageDate', 'RcNursEstDate', 'SeedingSowingTransplanting', 'Harv_date', 'Threshing_date']\n",
      "\t\t('object', ['text'])               :  2 | ['NursDetFactor', 'TransDetFactor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 12 | ['District', 'Block', 'LandPreparationMethod', 'CropEstMethod', 'TransplantingIrrigationSource', ...]\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['NursDetFactor', 'TransDetFactor']\n",
      "\t\t('float', [])                       : 14 | ['SeedlingsPerPit', 'TransplantingIrrigationHours', 'TransIrriCost', 'StandingWater', 'Ganaura', ...]\n",
      "\t\t('int', [])                         :  5 | ['CultLand', 'CropCultLand', 'CropTillageDepth', 'NoFertilizerAppln', 'Residue_length']\n",
      "\t\t('int', ['binned', 'text_special']) : 12 | ['NursDetFactor.char_count', 'NursDetFactor.word_count', 'NursDetFactor.capital_ratio', 'NursDetFactor.lower_ratio', 'NursDetFactor.symbol_count. ', ...]\n",
      "\t\t('int', ['bool'])                   :  3 | ['Harv_method', 'Threshing_method', 'Stubble_use']\n",
      "\t\t('int', ['datetime_as_int'])        : 22 | ['CropTillageDate', 'CropTillageDate.month', 'CropTillageDate.day', 'CropTillageDate.dayofweek', 'RcNursEstDate', ...]\n",
      "\t\t('int', ['text_ngram'])             : 56 | ['__nlp__.calendardate', '__nlp__.calendardate irrigwateravailability', '__nlp__.calendardate irrigwateravailability laboravailability', '__nlp__.calendardate irrigwateravailability labouravailability', '__nlp__.calendardate irrigwateravailability seedavailability', ...]\n",
      "\t0.8s = Fit runtime\n",
      "\t41 features in original data used to generate 126 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.85s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_epochs': 20},\n",
      "\t'GBM': {'num_boost_round': 40},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 2 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2365.51s of the 3549.15s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tunhashable type: 'list'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 692, in _calculate_total_resources\n",
      "    minimum_model_resources = self.get_minimum_resources(is_gpu_available=(num_gpus > 0))\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1262, in get_minimum_resources\n",
      "    return self._get_model_base().get_minimum_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 391, in get_minimum_resources\n",
      "    if is_gpu_available and self._is_gpu_lgbm_installed():\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 374, in _is_gpu_lgbm_installed\n",
      "    try_import_lightgbm()\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/compat.py\", line 147, in <module>\n",
      "    from dask.distributed import Client, Future, default_client, wait\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/dask/distributed.py\", line 13, in <module>\n",
      "    from distributed import *\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/__init__.py\", line 23, in <module>\n",
      "    from distributed.actor import Actor, ActorFuture, BaseActorFuture\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/actor.py\", line 13, in <module>\n",
      "    from distributed.client import Future\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/client.py\", line 118, in <module>\n",
      "    from distributed.worker import get_client, get_worker, secede\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker.py\", line 120, in <module>\n",
      "    from distributed.worker_memory import (\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker_memory.py\", line 56, in <module>\n",
      "    WorkerDataParameter: TypeAlias = Union[\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 243, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 316, in __getitem__\n",
      "    return self._getitem(self, parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 421, in Union\n",
      "    parameters = _remove_dups_flatten(parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 215, in _remove_dups_flatten\n",
      "    all_params = set(params)\n",
      "TypeError: unhashable type: 'list'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2365.4s of the 3549.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.01%)\n",
      "\t-157.3012\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3526.78s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t-157.3012\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 2 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3526.78s of the 3526.77s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tunhashable type: 'list'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 692, in _calculate_total_resources\n",
      "    minimum_model_resources = self.get_minimum_resources(is_gpu_available=(num_gpus > 0))\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1262, in get_minimum_resources\n",
      "    return self._get_model_base().get_minimum_resources(**kwargs)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 391, in get_minimum_resources\n",
      "    if is_gpu_available and self._is_gpu_lgbm_installed():\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 374, in _is_gpu_lgbm_installed\n",
      "    try_import_lightgbm()\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/lightgbm/compat.py\", line 147, in <module>\n",
      "    from dask.distributed import Client, Future, default_client, wait\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/dask/distributed.py\", line 13, in <module>\n",
      "    from distributed import *\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/__init__.py\", line 23, in <module>\n",
      "    from distributed.actor import Actor, ActorFuture, BaseActorFuture\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/actor.py\", line 13, in <module>\n",
      "    from distributed.client import Future\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/client.py\", line 118, in <module>\n",
      "    from distributed.worker import get_client, get_worker, secede\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker.py\", line 120, in <module>\n",
      "    from distributed.worker_memory import (\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/distributed/worker_memory.py\", line 56, in <module>\n",
      "    WorkerDataParameter: TypeAlias = Union[\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 243, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 316, in __getitem__\n",
      "    return self._getitem(self, parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 421, in Union\n",
      "    parameters = _remove_dups_flatten(parameters)\n",
      "  File \"/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/typing.py\", line 215, in _remove_dups_flatten\n",
      "    all_params = set(params)\n",
      "TypeError: unhashable type: 'list'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3526.66s of the 3526.66s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.01%)\n",
      "\t-156.3587\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.95s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3504.5s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L2': 0.533, 'NeuralNetTorch_BAG_L1': 0.467}\n",
      "\t-153.2496\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 45.55s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240303_155004\")\n"
     ]
    }
   ],
   "source": [
    "metric = 'root_mean_squared_error'  # specify the evaluation metric here, you can also use 'roc_auc', 'f1', etc.\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets='best_quality',\n",
    "    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1, ag_args_fit={'num_gpus': 1}, # Most of the models used by AutoGluon support GPU training, including LightGBM, CatBoost, XGBoost and FastAI Neural Network.\n",
    "    hyperparameters = {'NN_TORCH': {'num_epochs': 20}, 'GBM': {'num_boost_round': 40}} # last  argument is just for quick demo here, omit it in real applications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/content/sample_data'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label=label, path=save_path, num_gpus=1).fit(train_data, presets='best_quality', num_stack_levels=3, num_bag_folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model used by AutoML tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12363/850388021.py:1: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  predictor.get_model_best()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaderboard based on the training data   \n",
    "We can also use the customized metrics here by specifiying the extra_mertrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-174.167948</td>\n",
       "      <td>-174.167948</td>\n",
       "      <td>-156.358738</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.208874</td>\n",
       "      <td>0.199432</td>\n",
       "      <td>41.989415</td>\n",
       "      <td>0.104415</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[OrgFertilizers, CropTillageDepth, RcNursEstDa...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 20, 'epochs_wo_improve': 20, 'a...</td>\n",
       "      <td>{'batch_size': 64, 'num_epochs': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-176.541643</td>\n",
       "      <td>-176.541643</td>\n",
       "      <td>-153.249601</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.209858</td>\n",
       "      <td>0.199682</td>\n",
       "      <td>42.032229</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models'...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 100}</td>\n",
       "      <td>{'ensemble_size': 15}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-181.647965</td>\n",
       "      <td>-181.647965</td>\n",
       "      <td>-157.301221</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.104459</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>21.040712</td>\n",
       "      <td>0.104459</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[OrgFertilizers, CropTillageDepth, RcNursEstDa...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 20, 'epochs_wo_improve': 20, 'a...</td>\n",
       "      <td>{'batch_size': 64, 'num_epochs': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_BAG_L2, WeightedEnsemble_L2, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-181.647965</td>\n",
       "      <td>-181.647965</td>\n",
       "      <td>-157.301221</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.105213</td>\n",
       "      <td>0.098975</td>\n",
       "      <td>21.042385</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models'...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 100}</td>\n",
       "      <td>{'ensemble_size': 1}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  root_mean_squared_error   score_val  \\\n",
       "0  NeuralNetTorch_BAG_L2 -174.167948              -174.167948 -156.358738   \n",
       "1    WeightedEnsemble_L3 -176.541643              -176.541643 -153.249601   \n",
       "2  NeuralNetTorch_BAG_L1 -181.647965              -181.647965 -157.301221   \n",
       "3    WeightedEnsemble_L2 -181.647965              -181.647965 -157.301221   \n",
       "\n",
       "               eval_metric  pred_time_test  pred_time_val   fit_time  \\\n",
       "0  root_mean_squared_error        0.208874       0.199432  41.989415   \n",
       "1  root_mean_squared_error        0.209858       0.199682  42.032229   \n",
       "2  root_mean_squared_error        0.104459       0.098726  21.040712   \n",
       "3  root_mean_squared_error        0.105213       0.098975  21.042385   \n",
       "\n",
       "   pred_time_test_marginal  pred_time_val_marginal  ...  \\\n",
       "0                 0.104415                0.100705  ...   \n",
       "1                 0.000984                0.000251  ...   \n",
       "2                 0.104459                0.098726  ...   \n",
       "3                 0.000754                0.000249  ...   \n",
       "\n",
       "                                     hyperparameters  hyperparameters_fit  \\\n",
       "0  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "1  {'use_orig_features': False, 'max_base_models'...                   {}   \n",
       "2  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "3  {'use_orig_features': False, 'max_base_models'...                   {}   \n",
       "\n",
       "                                         ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "3  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "\n",
       "                                            features  compile_time  \\\n",
       "0  [OrgFertilizers, CropTillageDepth, RcNursEstDa...          None   \n",
       "1     [NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]          None   \n",
       "2  [OrgFertilizers, CropTillageDepth, RcNursEstDa...          None   \n",
       "3                            [NeuralNetTorch_BAG_L1]          None   \n",
       "\n",
       "                               child_hyperparameters  \\\n",
       "0  {'num_epochs': 20, 'epochs_wo_improve': 20, 'a...   \n",
       "1                             {'ensemble_size': 100}   \n",
       "2  {'num_epochs': 20, 'epochs_wo_improve': 20, 'a...   \n",
       "3                             {'ensemble_size': 100}   \n",
       "\n",
       "              child_hyperparameters_fit  \\\n",
       "0  {'batch_size': 64, 'num_epochs': 19}   \n",
       "1                 {'ensemble_size': 15}   \n",
       "2  {'batch_size': 64, 'num_epochs': 19}   \n",
       "3                  {'ensemble_size': 1}   \n",
       "\n",
       "                                   child_ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "3  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "\n",
       "                                        ancestors  \\\n",
       "0                         [NeuralNetTorch_BAG_L1]   \n",
       "1  [NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]   \n",
       "2                                              []   \n",
       "3                         [NeuralNetTorch_BAG_L1]   \n",
       "\n",
       "                                         descendants  \n",
       "0                              [WeightedEnsemble_L3]  \n",
       "1                                                 []  \n",
       "2  [NeuralNetTorch_BAG_L2, WeightedEnsemble_L2, W...  \n",
       "3                                                 []  \n",
       "\n",
       "[4 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(extra_info = True, silent=True, extra_metrics = ['root_mean_squared_error'], data=valid_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaderboard based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-174.167948</td>\n",
       "      <td>-156.358738</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.207926</td>\n",
       "      <td>0.199432</td>\n",
       "      <td>41.989415</td>\n",
       "      <td>0.104296</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>20.948703</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[OrgFertilizers, CropTillageDepth, RcNursEstDa...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 20, 'epochs_wo_improve': 20, 'a...</td>\n",
       "      <td>{'batch_size': 64, 'num_epochs': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-176.541643</td>\n",
       "      <td>-153.249601</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.208890</td>\n",
       "      <td>0.199682</td>\n",
       "      <td>42.032229</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.042814</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models'...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 100}</td>\n",
       "      <td>{'ensemble_size': 15}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-181.647965</td>\n",
       "      <td>-157.301221</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.103630</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>21.040712</td>\n",
       "      <td>0.103630</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>21.040712</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[OrgFertilizers, CropTillageDepth, RcNursEstDa...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 20, 'epochs_wo_improve': 20, 'a...</td>\n",
       "      <td>{'batch_size': 64, 'num_epochs': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NeuralNetTorch_BAG_L2, WeightedEnsemble_L2, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-181.647965</td>\n",
       "      <td>-157.301221</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.104384</td>\n",
       "      <td>0.098975</td>\n",
       "      <td>21.042385</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models'...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 100}</td>\n",
       "      <td>{'ensemble_size': 1}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[NeuralNetTorch_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test   score_val              eval_metric  \\\n",
       "0  NeuralNetTorch_BAG_L2 -174.167948 -156.358738  root_mean_squared_error   \n",
       "1    WeightedEnsemble_L3 -176.541643 -153.249601  root_mean_squared_error   \n",
       "2  NeuralNetTorch_BAG_L1 -181.647965 -157.301221  root_mean_squared_error   \n",
       "3    WeightedEnsemble_L2 -181.647965 -157.301221  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0        0.207926       0.199432  41.989415                 0.104296   \n",
       "1        0.208890       0.199682  42.032229                 0.000964   \n",
       "2        0.103630       0.098726  21.040712                 0.103630   \n",
       "3        0.104384       0.098975  21.042385                 0.000754   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  ...  \\\n",
       "0                0.100705          20.948703  ...   \n",
       "1                0.000251           0.042814  ...   \n",
       "2                0.098726          21.040712  ...   \n",
       "3                0.000249           0.001673  ...   \n",
       "\n",
       "                                     hyperparameters  hyperparameters_fit  \\\n",
       "0  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "1  {'use_orig_features': False, 'max_base_models'...                   {}   \n",
       "2  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "3  {'use_orig_features': False, 'max_base_models'...                   {}   \n",
       "\n",
       "                                         ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "3  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "\n",
       "                                            features  compile_time  \\\n",
       "0  [OrgFertilizers, CropTillageDepth, RcNursEstDa...          None   \n",
       "1     [NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]          None   \n",
       "2  [OrgFertilizers, CropTillageDepth, RcNursEstDa...          None   \n",
       "3                            [NeuralNetTorch_BAG_L1]          None   \n",
       "\n",
       "                               child_hyperparameters  \\\n",
       "0  {'num_epochs': 20, 'epochs_wo_improve': 20, 'a...   \n",
       "1                             {'ensemble_size': 100}   \n",
       "2  {'num_epochs': 20, 'epochs_wo_improve': 20, 'a...   \n",
       "3                             {'ensemble_size': 100}   \n",
       "\n",
       "              child_hyperparameters_fit  \\\n",
       "0  {'batch_size': 64, 'num_epochs': 19}   \n",
       "1                 {'ensemble_size': 15}   \n",
       "2  {'batch_size': 64, 'num_epochs': 19}   \n",
       "3                  {'ensemble_size': 1}   \n",
       "\n",
       "                                   child_ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "3  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "\n",
       "                                        ancestors  \\\n",
       "0                         [NeuralNetTorch_BAG_L1]   \n",
       "1  [NeuralNetTorch_BAG_L2, NeuralNetTorch_BAG_L1]   \n",
       "2                                              []   \n",
       "3                         [NeuralNetTorch_BAG_L1]   \n",
       "\n",
       "                                         descendants  \n",
       "0                              [WeightedEnsemble_L3]  \n",
       "1                                                 []  \n",
       "2  [NeuralNetTorch_BAG_L2, WeightedEnsemble_L2, W...  \n",
       "3                                                 []  \n",
       "\n",
       "[4 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(valid_data, extra_info = True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                   model   score_val              eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L3 -153.249601  root_mean_squared_error       0.199682  42.032229                0.000251           0.042814            3       True          4\n",
      "1  NeuralNetTorch_BAG_L2 -156.358738  root_mean_squared_error       0.199432  41.989415                0.100705          20.948703            2       True          3\n",
      "2  NeuralNetTorch_BAG_L1 -157.301221  root_mean_squared_error       0.098726  21.040712                0.098726          21.040712            1       True          1\n",
      "3    WeightedEnsemble_L2 -157.301221  root_mean_squared_error       0.098975  21.042385                0.000249           0.001673            2       True          2\n",
      "Number of models trained: 4\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_TabularNeuralNetTorch'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    : 12 | ['District', 'Block', 'LandPreparationMethod', 'CropEstMethod', 'TransplantingIrrigationSource', ...]\n",
      "('category', ['text_as_category'])  :  2 | ['NursDetFactor', 'TransDetFactor']\n",
      "('float', [])                       : 14 | ['SeedlingsPerPit', 'TransplantingIrrigationHours', 'TransIrriCost', 'StandingWater', 'Ganaura', ...]\n",
      "('int', [])                         :  5 | ['CultLand', 'CropCultLand', 'CropTillageDepth', 'NoFertilizerAppln', 'Residue_length']\n",
      "('int', ['binned', 'text_special']) : 12 | ['NursDetFactor.char_count', 'NursDetFactor.word_count', 'NursDetFactor.capital_ratio', 'NursDetFactor.lower_ratio', 'NursDetFactor.symbol_count. ', ...]\n",
      "('int', ['bool'])                   :  3 | ['Harv_method', 'Threshing_method', 'Stubble_use']\n",
      "('int', ['datetime_as_int'])        : 22 | ['CropTillageDate', 'CropTillageDate.month', 'CropTillageDate.day', 'CropTillageDate.dayofweek', 'RcNursEstDate', ...]\n",
      "('int', ['text_ngram'])             : 56 | ['__nlp__.calendardate', '__nlp__.calendardate irrigwateravailability', '__nlp__.calendardate irrigwateravailability laboravailability', '__nlp__.calendardate irrigwateravailability labouravailability', '__nlp__.calendardate irrigwateravailability seedavailability', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmmista-wap266/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12363/278995493.py:1: DeprecationWarning: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead. This will raise an error in the future!\n",
      "  all_models = predictor.get_model_names()\n"
     ]
    }
   ],
   "source": [
    "all_models = predictor.get_model_names()\n",
    "model_to_use = all_models[1]\n",
    "specific_model = predictor._trainer.load_model(model_to_use)\n",
    "\n",
    "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
    "model_info = specific_model.get_info()\n",
    "predictor_information = predictor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ID', 'Residue_perc']\n",
      "Computing feature importance via permutation shuffling for 41 features using 620 rows with 5 shuffle sets...\n",
      "\t52.59s\t= Expected runtime (10.52s per shuffle set)\n",
      "\t11.57s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acre</th>\n",
       "      <td>202.951906</td>\n",
       "      <td>7.507885</td>\n",
       "      <td>2.243299e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>218.410745</td>\n",
       "      <td>187.493067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BasalDAP</th>\n",
       "      <td>21.892375</td>\n",
       "      <td>2.269117</td>\n",
       "      <td>1.365343e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>26.564519</td>\n",
       "      <td>17.220232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harv_hand_rent</th>\n",
       "      <td>19.058098</td>\n",
       "      <td>6.199579</td>\n",
       "      <td>1.173254e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>31.823117</td>\n",
       "      <td>6.293080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1tdUrea</th>\n",
       "      <td>15.259450</td>\n",
       "      <td>4.913006</td>\n",
       "      <td>1.128892e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>25.375397</td>\n",
       "      <td>5.143502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransplantingIrrigationHours</th>\n",
       "      <td>8.219635</td>\n",
       "      <td>2.577771</td>\n",
       "      <td>1.022915e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>13.527302</td>\n",
       "      <td>2.911968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandPreparationMethod</th>\n",
       "      <td>7.578699</td>\n",
       "      <td>2.474369</td>\n",
       "      <td>1.189393e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>12.673459</td>\n",
       "      <td>2.483938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harv_date</th>\n",
       "      <td>7.497262</td>\n",
       "      <td>2.720987</td>\n",
       "      <td>1.761199e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>13.099812</td>\n",
       "      <td>1.894712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threshing_date</th>\n",
       "      <td>7.388973</td>\n",
       "      <td>2.118219</td>\n",
       "      <td>7.287487e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>11.750415</td>\n",
       "      <td>3.027532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block</th>\n",
       "      <td>7.194203</td>\n",
       "      <td>2.152182</td>\n",
       "      <td>8.563338e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>11.625576</td>\n",
       "      <td>2.762831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CropCultLand</th>\n",
       "      <td>6.795520</td>\n",
       "      <td>1.947921</td>\n",
       "      <td>7.285066e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>10.806317</td>\n",
       "      <td>2.784724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NursDetFactor</th>\n",
       "      <td>6.339730</td>\n",
       "      <td>1.326989</td>\n",
       "      <td>2.174777e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>9.072020</td>\n",
       "      <td>3.607441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CropbasalFerts</th>\n",
       "      <td>5.594451</td>\n",
       "      <td>3.341162</td>\n",
       "      <td>1.002494e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>12.473949</td>\n",
       "      <td>-1.285048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District</th>\n",
       "      <td>5.153535</td>\n",
       "      <td>0.870527</td>\n",
       "      <td>9.409047e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>6.945963</td>\n",
       "      <td>3.361107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ganaura</th>\n",
       "      <td>4.669735</td>\n",
       "      <td>2.631103</td>\n",
       "      <td>8.278897e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>10.087212</td>\n",
       "      <td>-0.747742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residue_length</th>\n",
       "      <td>3.961844</td>\n",
       "      <td>1.512381</td>\n",
       "      <td>2.119519e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>7.075857</td>\n",
       "      <td>0.847830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FirstTopDressFert</th>\n",
       "      <td>3.766263</td>\n",
       "      <td>0.578227</td>\n",
       "      <td>6.462575e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>4.956840</td>\n",
       "      <td>2.575685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransDetFactor</th>\n",
       "      <td>3.655753</td>\n",
       "      <td>1.596702</td>\n",
       "      <td>3.443966e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>6.943384</td>\n",
       "      <td>0.368122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MineralFertAppMethod</th>\n",
       "      <td>3.066519</td>\n",
       "      <td>1.128370</td>\n",
       "      <td>1.852696e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>5.389849</td>\n",
       "      <td>0.743189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeedlingsPerPit</th>\n",
       "      <td>2.327119</td>\n",
       "      <td>1.092068</td>\n",
       "      <td>4.436603e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4.575701</td>\n",
       "      <td>0.078536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2tdUrea</th>\n",
       "      <td>2.190688</td>\n",
       "      <td>1.320353</td>\n",
       "      <td>1.032690e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>4.909314</td>\n",
       "      <td>-0.527937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeedingSowingTransplanting</th>\n",
       "      <td>2.124993</td>\n",
       "      <td>0.838042</td>\n",
       "      <td>2.386278e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>3.850533</td>\n",
       "      <td>0.399454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CropOrgFYM</th>\n",
       "      <td>2.088186</td>\n",
       "      <td>2.846486</td>\n",
       "      <td>8.813472e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>7.949140</td>\n",
       "      <td>-3.772769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCropSolidOrgFertAppMethod</th>\n",
       "      <td>2.009711</td>\n",
       "      <td>0.596152</td>\n",
       "      <td>8.294047e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>3.237197</td>\n",
       "      <td>0.782225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrgFertilizers</th>\n",
       "      <td>2.005457</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>2.585378e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>3.670363</td>\n",
       "      <td>0.340551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CultLand</th>\n",
       "      <td>1.854999</td>\n",
       "      <td>0.600672</td>\n",
       "      <td>1.153326e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>3.091791</td>\n",
       "      <td>0.618208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandingWater</th>\n",
       "      <td>1.731744</td>\n",
       "      <td>1.093831</td>\n",
       "      <td>1.200538e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>3.983958</td>\n",
       "      <td>-0.520470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransIrriCost</th>\n",
       "      <td>1.559695</td>\n",
       "      <td>1.231081</td>\n",
       "      <td>2.360195e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>4.094508</td>\n",
       "      <td>-0.975118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransplantingIrrigationPowerSource</th>\n",
       "      <td>1.431925</td>\n",
       "      <td>0.365329</td>\n",
       "      <td>4.671465e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>2.184143</td>\n",
       "      <td>0.679708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harv_method</th>\n",
       "      <td>0.921937</td>\n",
       "      <td>0.134662</td>\n",
       "      <td>5.310160e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.199209</td>\n",
       "      <td>0.644665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CropEstMethod</th>\n",
       "      <td>0.659484</td>\n",
       "      <td>0.820901</td>\n",
       "      <td>7.342779e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>2.349730</td>\n",
       "      <td>-1.030762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RcNursEstDate</th>\n",
       "      <td>0.306131</td>\n",
       "      <td>0.981553</td>\n",
       "      <td>2.619828e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2.327161</td>\n",
       "      <td>-1.714899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CropTillageDepth</th>\n",
       "      <td>0.229235</td>\n",
       "      <td>0.632789</td>\n",
       "      <td>2.316768e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1.532156</td>\n",
       "      <td>-1.073686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BasalUrea</th>\n",
       "      <td>0.111651</td>\n",
       "      <td>1.033130</td>\n",
       "      <td>4.104657e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2.238881</td>\n",
       "      <td>-2.015579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransplantingIrrigationSource</th>\n",
       "      <td>0.069543</td>\n",
       "      <td>0.148024</td>\n",
       "      <td>1.763746e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.374326</td>\n",
       "      <td>-0.235239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stubble_use</th>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.042575</td>\n",
       "      <td>2.838632e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>-0.075822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1appDaysUrea</th>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.553684</td>\n",
       "      <td>4.882969e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1.147773</td>\n",
       "      <td>-1.132315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MineralFertAppMethod.1</th>\n",
       "      <td>-0.013519</td>\n",
       "      <td>1.229605</td>\n",
       "      <td>5.092181e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2.518255</td>\n",
       "      <td>-2.545294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoFertilizerAppln</th>\n",
       "      <td>-0.087383</td>\n",
       "      <td>1.402799</td>\n",
       "      <td>5.520235e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2.801000</td>\n",
       "      <td>-2.975767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2appDaysUrea</th>\n",
       "      <td>-0.090785</td>\n",
       "      <td>1.455941</td>\n",
       "      <td>5.520754e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2.907017</td>\n",
       "      <td>-3.088587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threshing_method</th>\n",
       "      <td>-1.018713</td>\n",
       "      <td>0.973820</td>\n",
       "      <td>9.602740e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986395</td>\n",
       "      <td>-3.023822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CropTillageDate</th>\n",
       "      <td>-1.430006</td>\n",
       "      <td>1.208578</td>\n",
       "      <td>9.713822e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1.058473</td>\n",
       "      <td>-3.918485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance    stddev       p_value  n  \\\n",
       "Acre                                202.951906  7.507885  2.243299e-07  5   \n",
       "BasalDAP                             21.892375  2.269117  1.365343e-05  5   \n",
       "Harv_hand_rent                       19.058098  6.199579  1.173254e-03  5   \n",
       "1tdUrea                              15.259450  4.913006  1.128892e-03  5   \n",
       "TransplantingIrrigationHours          8.219635  2.577771  1.022915e-03  5   \n",
       "LandPreparationMethod                 7.578699  2.474369  1.189393e-03  5   \n",
       "Harv_date                             7.497262  2.720987  1.761199e-03  5   \n",
       "Threshing_date                        7.388973  2.118219  7.287487e-04  5   \n",
       "Block                                 7.194203  2.152182  8.563338e-04  5   \n",
       "CropCultLand                          6.795520  1.947921  7.285066e-04  5   \n",
       "NursDetFactor                         6.339730  1.326989  2.174777e-04  5   \n",
       "CropbasalFerts                        5.594451  3.341162  1.002494e-02  5   \n",
       "District                              5.153535  0.870527  9.409047e-05  5   \n",
       "Ganaura                               4.669735  2.631103  8.278897e-03  5   \n",
       "Residue_length                        3.961844  1.512381  2.119519e-03  5   \n",
       "FirstTopDressFert                     3.766263  0.578227  6.462575e-05  5   \n",
       "TransDetFactor                        3.655753  1.596702  3.443966e-03  5   \n",
       "MineralFertAppMethod                  3.066519  1.128370  1.852696e-03  5   \n",
       "SeedlingsPerPit                       2.327119  1.092068  4.436603e-03  5   \n",
       "2tdUrea                               2.190688  1.320353  1.032690e-02  5   \n",
       "SeedingSowingTransplanting            2.124993  0.838042  2.386278e-03  5   \n",
       "CropOrgFYM                            2.088186  2.846486  8.813472e-02  5   \n",
       "PCropSolidOrgFertAppMethod            2.009711  0.596152  8.294047e-04  5   \n",
       "OrgFertilizers                        2.005457  0.808594  2.585378e-03  5   \n",
       "CultLand                              1.854999  0.600672  1.153326e-03  5   \n",
       "StandingWater                         1.731744  1.093831  1.200538e-02  5   \n",
       "TransIrriCost                         1.559695  1.231081  2.360195e-02  5   \n",
       "TransplantingIrrigationPowerSource    1.431925  0.365329  4.671465e-04  5   \n",
       "Harv_method                           0.921937  0.134662  5.310160e-05  5   \n",
       "CropEstMethod                         0.659484  0.820901  7.342779e-02  5   \n",
       "RcNursEstDate                         0.306131  0.981553  2.619828e-01  5   \n",
       "CropTillageDepth                      0.229235  0.632789  2.316768e-01  5   \n",
       "BasalUrea                             0.111651  1.033130  4.104657e-01  5   \n",
       "TransplantingIrrigationSource         0.069543  0.148024  1.763746e-01  5   \n",
       "Stubble_use                           0.011840  0.042575  2.838632e-01  5   \n",
       "1appDaysUrea                          0.007729  0.553684  4.882969e-01  5   \n",
       "MineralFertAppMethod.1               -0.013519  1.229605  5.092181e-01  5   \n",
       "NoFertilizerAppln                    -0.087383  1.402799  5.520235e-01  5   \n",
       "2appDaysUrea                         -0.090785  1.455941  5.520754e-01  5   \n",
       "Threshing_method                     -1.018713  0.973820  9.602740e-01  5   \n",
       "CropTillageDate                      -1.430006  1.208578  9.713822e-01  5   \n",
       "\n",
       "                                      p99_high     p99_low  \n",
       "Acre                                218.410745  187.493067  \n",
       "BasalDAP                             26.564519   17.220232  \n",
       "Harv_hand_rent                       31.823117    6.293080  \n",
       "1tdUrea                              25.375397    5.143502  \n",
       "TransplantingIrrigationHours         13.527302    2.911968  \n",
       "LandPreparationMethod                12.673459    2.483938  \n",
       "Harv_date                            13.099812    1.894712  \n",
       "Threshing_date                       11.750415    3.027532  \n",
       "Block                                11.625576    2.762831  \n",
       "CropCultLand                         10.806317    2.784724  \n",
       "NursDetFactor                         9.072020    3.607441  \n",
       "CropbasalFerts                       12.473949   -1.285048  \n",
       "District                              6.945963    3.361107  \n",
       "Ganaura                              10.087212   -0.747742  \n",
       "Residue_length                        7.075857    0.847830  \n",
       "FirstTopDressFert                     4.956840    2.575685  \n",
       "TransDetFactor                        6.943384    0.368122  \n",
       "MineralFertAppMethod                  5.389849    0.743189  \n",
       "SeedlingsPerPit                       4.575701    0.078536  \n",
       "2tdUrea                               4.909314   -0.527937  \n",
       "SeedingSowingTransplanting            3.850533    0.399454  \n",
       "CropOrgFYM                            7.949140   -3.772769  \n",
       "PCropSolidOrgFertAppMethod            3.237197    0.782225  \n",
       "OrgFertilizers                        3.670363    0.340551  \n",
       "CultLand                              3.091791    0.618208  \n",
       "StandingWater                         3.983958   -0.520470  \n",
       "TransIrriCost                         4.094508   -0.975118  \n",
       "TransplantingIrrigationPowerSource    2.184143    0.679708  \n",
       "Harv_method                           1.199209    0.644665  \n",
       "CropEstMethod                         2.349730   -1.030762  \n",
       "RcNursEstDate                         2.327161   -1.714899  \n",
       "CropTillageDepth                      1.532156   -1.073686  \n",
       "BasalUrea                             2.238881   -2.015579  \n",
       "TransplantingIrrigationSource         0.374326   -0.235239  \n",
       "Stubble_use                           0.099502   -0.075822  \n",
       "1appDaysUrea                          1.147773   -1.132315  \n",
       "MineralFertAppMethod.1                2.518255   -2.545294  \n",
       "NoFertilizerAppln                     2.801000   -2.975767  \n",
       "2appDaysUrea                          2.907017   -3.088587  \n",
       "Threshing_method                      0.986395   -3.023822  \n",
       "CropTillageDate                       1.058473   -3.918485  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(valid_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

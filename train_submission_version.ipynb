{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# Use ensemble to train the model\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import sys\n",
    "\n",
    "# In the second part of the notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# This part of importing would be moved to main.py or train.py later\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_option():\n",
    "    parse = argparse.ArgumentParser(\"Zindi Competition\", add_help=False)\n",
    "    parse.add_argument('--num_leaves', type=int, help=\"number of leaves in the tree model\")\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()\n",
    "    parse.add_argument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a hyperparameter class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.objective = 'regression'\n",
    "        self.num_leaves = 31\n",
    "        self.learning_rate = 0.01\n",
    "        self.n_estimators = 120\n",
    "        self.max_bin = 255\n",
    "        self.bagging_fraction = 0.8\n",
    "        self.bagging_freq = 5\n",
    "        self.feature_fraction = 0.8\n",
    "        self.feature_fraction_seed = 9\n",
    "        self.bagging_seed = 9\n",
    "        self.random_state = 42\n",
    "        self.OrgFertilizers = 'None'\n",
    "        self.FirstTopDressFert = 'None' \n",
    "        self.CropbasalFerts = 'None'\n",
    "        self.NursDetFactor = 'None'\n",
    "        self.LandPreparationMethod = 'None'\n",
    "        self.TransDetFactor = 'None'\n",
    "        self.PCropSolidOrgFertAppMethod = 'None'\n",
    "        self.sparse_threshold = 1.0\n",
    "# Instantiate the Hyperparameters class\n",
    "config = Config()\n",
    "\n",
    "# Initialize a wandb run\n",
    "wandb.init(project='zindi-crop-challenge',\n",
    "           entity=\"lmu-seminar\")\n",
    "\n",
    "# Update the wandb configuration with the hyperparameters\n",
    "wandb.config.update(vars(config))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'Test.csv'\n",
    "dataset_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'Yield' column and drop it\n",
    "# Load the test dataset\n",
    "path = 'Train.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "train_labels = dataset['Yield'].copy()\n",
    "dataset = dataset.drop(columns=['ID','Yield'], axis = 1)\n",
    "ID = dataset_test['ID'].copy()\n",
    "dataset_test = dataset_test.drop(columns=['ID'], axis = 1)\n",
    "\n",
    "# Load the test dataset\n",
    "test_path = 'Test.csv'\n",
    "dataset_test = pd.read_csv(test_path)\n",
    "dataset_upload = dataset_test.copy()\n",
    "dataset_test = dataset_test.drop(columns=['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "path = 'Train.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "train_labels = dataset['Yield'].copy()\n",
    "dataset = dataset.drop(columns=['ID','Yield'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Harv_hand_rent'] = dataset['Harv_hand_rent'].fillna(0)\n",
    "dataset['OrgFertilizers'] = dataset['OrgFertilizers'].fillna(dataset['OrgFertilizers'].mode()[0])\n",
    "dataset['CropbasalFerts'] = dataset['CropbasalFerts'].fillna(dataset['CropbasalFerts'].mode()[0])\n",
    "dataset['FirstTopDressFert'] = dataset['FirstTopDressFert'].fillna(dataset['FirstTopDressFert'].mode()[0])\n",
    "dataset['NursDetFactor'] = dataset['NursDetFactor'].fillna(dataset['NursDetFactor'].mode()[0])\n",
    "dataset['LandPreparationMethod'] = dataset['LandPreparationMethod'].fillna(dataset['LandPreparationMethod'].mode()[0])\n",
    "dataset['TransDetFactor'] = dataset['TransDetFactor'].fillna(dataset['TransDetFactor'].mode()[0])\n",
    "dataset['PCropSolidOrgFertAppMethod'] = dataset['PCropSolidOrgFertAppMethod'].fillna(dataset['PCropSolidOrgFertAppMethod'].mode()[0])\n",
    "\n",
    "dataset_test['Harv_hand_rent'] = dataset_test['Harv_hand_rent'].fillna(0)\n",
    "dataset_test['OrgFertilizers'] = dataset_test['OrgFertilizers'].fillna(dataset_test['OrgFertilizers'].mode()[0])\n",
    "dataset_test['CropbasalFerts'] = dataset_test['CropbasalFerts'].fillna(dataset_test['CropbasalFerts'].mode()[0])\n",
    "dataset_test['FirstTopDressFert'] = dataset_test['FirstTopDressFert'].fillna(dataset_test['FirstTopDressFert'].mode()[0])\n",
    "dataset_test['NursDetFactor'] = dataset_test['NursDetFactor'].fillna(dataset_test['NursDetFactor'].mode()[0])\n",
    "dataset_test['LandPreparationMethod'] = dataset_test['LandPreparationMethod'].fillna(dataset_test['LandPreparationMethod'].mode()[0])\n",
    "dataset_test['TransDetFactor'] = dataset_test['TransDetFactor'].fillna(dataset_test['TransDetFactor'].mode()[0])\n",
    "dataset_test['PCropSolidOrgFertAppMethod'] = dataset_test['PCropSolidOrgFertAppMethod'].fillna(dataset_test['PCropSolidOrgFertAppMethod'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values for categorical variables to identify sparse classes\n",
    "categorical_columns = dataset.select_dtypes(include=['object']).columns\n",
    "sparse_classes = {col: dataset[col].nunique() for col in categorical_columns if dataset[col].nunique() > 15} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['LandPreparationMethod', 'CropTillageDate', 'RcNursEstDate', 'SeedingSowingTransplanting', 'NursDetFactor', 'TransDetFactor', 'OrgFertilizers', 'CropbasalFerts', 'Harv_date', 'Threshing_date'])\n"
     ]
    }
   ],
   "source": [
    "# check the name of sparse classes\n",
    "print(sparse_classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([43, 78, 61, 62, 125, 155, 31, 34, 107, 162])\n"
     ]
    }
   ],
   "source": [
    "# check the unique values of sparse classes\n",
    "print(sparse_classes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for grouping\n",
    "threshold_percentage = 1\n",
    "threshold = len(dataset) * (threshold_percentage / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group sparse classes\n",
    "def group_sparse_classes(df, column, threshold):\n",
    "    # Find the categories that are below the threshold\n",
    "    value_counts = df[column].value_counts()\n",
    "    to_replace = value_counts[value_counts <= threshold].index.tolist()\n",
    "    \n",
    "    # Replace the sparse classes with 'other'\n",
    "    df[column] = df[column].replace(to_replace, 'other')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply grouping for the identified categorical variables with many unique values\n",
    "for col in ['LandPreparationMethod', 'OrgFertilizers', 'CropbasalFerts']:\n",
    "    dataset = group_sparse_classes(dataset, col, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the category adjustment to the test dataset based on the training dataset categories\n",
    "for col in ['LandPreparationMethod', 'OrgFertilizers', 'CropbasalFerts']:\n",
    "    test_dataset = group_sparse_classes(dataset_test, col, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 skewed numerical features to Box Cox transform\n",
      "CultLand                         8.178796\n",
      "CropCultLand                     8.796317\n",
      "SeedlingsPerPit                 53.528364\n",
      "TransplantingIrrigationHours    30.754264\n",
      "TransIrriCost                    3.912326\n",
      "StandingWater                    1.848641\n",
      "Ganaura                          5.237242\n",
      "CropOrgFYM                       6.876849\n",
      "BasalDAP                         2.905715\n",
      "BasalUrea                        2.244465\n",
      "1tdUrea                          2.094479\n",
      "1appDaysUrea                     4.769872\n",
      "2tdUrea                          2.696580\n",
      "2appDaysUrea                    -1.589283\n",
      "Harv_hand_rent                  40.547049\n",
      "Residue_length                  -1.880371\n",
      "Residue_perc                     3.747956\n",
      "Acre                             2.384037\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# fill the high skewness columns with median\n",
    "# check the skewness of the numerical columns\n",
    "skewness = dataset.skew(numeric_only=True)\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "# sort the skewness in descending order\n",
    "skewness.sort_values(ascending=False)\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_skewed_features = ['SeedlingsPerPit', 'TransplantingIrrigationHours','Harv_hand_rent']\n",
    "low_skewed_features = ['CultLand', 'CropOrgFYM', 'CropCultLand','Ganaura'] \n",
    "moderate_skewed_features = ['BasalUrea', 'BasalDAP',\n",
    "                            '1tdUrea', '1appDaysUrea', \n",
    "                            '2tdUrea', '2appDaysUrea',\n",
    "                            'Residue_length', 'Residue_perc',\n",
    "                            'StandingWater', 'TransIrriCost',\n",
    "                            'TransIrriCost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeedlingsPerPit                 float64\n",
      "TransplantingIrrigationHours    float64\n",
      "Harv_hand_rent                  float64\n",
      "dtype: object\n",
      "CultLand          int64\n",
      "CropOrgFYM      float64\n",
      "CropCultLand      int64\n",
      "Ganaura         float64\n",
      "dtype: object\n",
      "BasalUrea         float64\n",
      "BasalDAP          float64\n",
      "1tdUrea           float64\n",
      "1appDaysUrea      float64\n",
      "2tdUrea           float64\n",
      "2appDaysUrea      float64\n",
      "Residue_length      int64\n",
      "Residue_perc        int64\n",
      "StandingWater     float64\n",
      "TransIrriCost     float64\n",
      "TransIrriCost     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the dtype of those skewed features\n",
    "print(dataset[high_skewed_features].dtypes)\n",
    "print(dataset[low_skewed_features].dtypes)\n",
    "print(dataset[moderate_skewed_features].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the low skewness columns with mean\n",
    "for feat in low_skewed_features:\n",
    "    dataset[feat] = dataset[feat].fillna(dataset[feat].mean())\n",
    "    dataset_test[feat] = dataset_test[feat].fillna(dataset_test[feat].mean())\n",
    "\n",
    "# Fill the moderate skewness columns with median\n",
    "for feat in moderate_skewed_features:\n",
    "    dataset[feat] = dataset[feat].fillna(dataset[feat].median())\n",
    "    dataset_test[feat] = dataset_test[feat].fillna(dataset_test[feat].median())\n",
    "\n",
    "# Fill the high skewness columns with median\n",
    "for feat in high_skewed_features:\n",
    "    dataset[feat] = dataset[feat].fillna(dataset[feat].median())\n",
    "    dataset_test[feat] = dataset_test[feat].fillna(dataset_test[feat].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nskewed_features = skewness.index\\nlam = 0.15\\n# apply the boxcox1p transformation to the skewed features\\nfor feat in skewed_features:\\n    dataset[feat] = boxcox1p(dataset[feat], lam)\\n    dataset_test[feat] = boxcox1p(dataset_test[feat], lam)\\n\\n# check the skewness of the numerical columns\\nskewness = dataset.skew(numeric_only=True)\\nskewness = skewness[abs(skewness) > 0.5]\\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "# apply the boxcox1p transformation to the skewed features\n",
    "for feat in skewed_features:\n",
    "    dataset[feat] = boxcox1p(dataset[feat], lam)\n",
    "    dataset_test[feat] = boxcox1p(dataset_test[feat], lam)\n",
    "\n",
    "# check the skewness of the numerical columns\n",
    "skewness = dataset.skew(numeric_only=True)\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbins_SeedlingsPerPit = [0, 2, 4, np.inf]\\nlabels_SeedlingsPerPit = ['Low', 'Medium', 'High']\\ndataset['SeedlingsPerPit_Binned'] = pd.cut(dataset['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\\ndataset_test['SeedlingsPerPit_Binned'] = pd.cut(dataset_test['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bins_SeedlingsPerPit = [0, 2, 4, np.inf]\n",
    "labels_SeedlingsPerPit = ['Low', 'Medium', 'High']\n",
    "dataset['SeedlingsPerPit_Binned'] = pd.cut(dataset['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\n",
    "dataset_test['SeedlingsPerPit_Binned'] = pd.cut(dataset_test['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbins_NoFertilizerAppln = [0, 1, 2, np.inf]\\nlabels_NoFertilizerAppln = ['Low', 'Medium', 'High']\\ndataset['NoFertilizerAppln_Binned'] = pd.cut(dataset['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\\ndataset_test['NoFertilizerAppln_Binned'] = pd.cut(dataset_test['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bins_NoFertilizerAppln = [0, 1, 2, np.inf]\n",
    "labels_NoFertilizerAppln = ['Low', 'Medium', 'High']\n",
    "dataset['NoFertilizerAppln_Binned'] = pd.cut(dataset['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\n",
    "dataset_test['NoFertilizerAppln_Binned'] = pd.cut(dataset_test['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RcNursEstDate is NaN, then fill NursDetFactor with None\n",
    "# if RcNursEstDate is not NaN, then fill NursDetFactor with mode\n",
    "dataset.loc[dataset['RcNursEstDate'].isnull(), 'NursDetFactor'] = 'None'\n",
    "dataset.loc[dataset['RcNursEstDate'].notnull(), 'NursDetFactor'] = dataset['NursDetFactor'].mode()[0]\n",
    "\n",
    "dataset_test.loc[dataset_test['RcNursEstDate'].isnull(), 'NursDetFactor'] = 'None'\n",
    "dataset_test.loc[dataset_test['RcNursEstDate'].notnull(), 'NursDetFactor'] = dataset_test['NursDetFactor'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing value with MineralFertAppMethod.1 with mode\n",
    "dataset['MineralFertAppMethod.1'] = dataset['MineralFertAppMethod.1'].fillna(dataset['MineralFertAppMethod.1'].mode()[0])\n",
    "dataset_test['MineralFertAppMethod.1'] = dataset_test['MineralFertAppMethod.1'].fillna(dataset_test['MineralFertAppMethod.1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date columns\n",
    "date_columns = ['Harv_date', 'SeedingSowingTransplanting', 'RcNursEstDate', 'Threshing_date', 'CropTillageDate']\n",
    "\n",
    "# fill the missing values with mode\n",
    "for col in date_columns:\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].mode()[0])\n",
    "    dataset_test[col] = dataset_test[col].fillna(dataset_test[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date columns to datetime\n",
    "for col in date_columns:\n",
    "    dataset[col] = pd.to_datetime(dataset[col])\n",
    "    dataset_test[col] = pd.to_datetime(dataset_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Harv_date_RcNursEstDate'] = (dataset['Harv_date'] - dataset['RcNursEstDate']).dt.days\n",
    "dataset_test['Harv_date_RcNursEstDate'] = (dataset_test['Harv_date'] - dataset_test['RcNursEstDate']).dt.days\n",
    "dataset.loc[dataset['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] = dataset.loc[dataset['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] + 365\n",
    "dataset_test.loc[dataset_test['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] = dataset_test.loc[dataset_test['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] + 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harvest_date - CropTillageDate\n",
    "dataset['CropTillageDate'] = pd.to_datetime(dataset['CropTillageDate'])\n",
    "dataset_test['CropTillageDate'] = pd.to_datetime(dataset_test['CropTillageDate'])\n",
    "dataset['Harv_date_CropTillageDate'] = (dataset['Harv_date'] - dataset['CropTillageDate']).dt.days\n",
    "dataset_test['Harv_date_CropTillageDate'] = (dataset_test['Harv_date'] - dataset_test['CropTillageDate']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshing_date - Harvest_date\n",
    "dataset['Threshing_date'] = pd.to_datetime(dataset['Threshing_date'])\n",
    "dataset['Threshing_date_Harv_date'] = (dataset['Threshing_date'] - dataset['Harv_date']).dt.days\n",
    "dataset_test['Threshing_date'] = pd.to_datetime(dataset_test['Threshing_date'])\n",
    "dataset_test['Threshing_date_Harv_date'] = (dataset_test['Threshing_date'] - dataset_test['Harv_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the month features, this will be transfered into one-hot encoding later\n",
    "dataset['Harv_date_Month'] = dataset['Harv_date'].dt.month\n",
    "dataset_test['Harv_date_Month'] = dataset_test['Harv_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the month values to the season values\n",
    "month_to_season = {1: 1, 2: 1, 3: 1, 4: 2, 5: 2,\n",
    "                     6: 2, 7: 3, 8: 3, 9: 3, 10: 4,\n",
    "                     11: 4, 12: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the month values to the season values\n",
    "dataset['Harv_date_Season'] = dataset['Harv_date_Month'].map(month_to_season)\n",
    "dataset_test['Harv_date_Season'] = dataset_test['Harv_date_Month'].map(month_to_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Harv_date_Month'], axis=1)\n",
    "dataset_test = dataset_test.drop(columns=['Harv_date_Month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original date columns\n",
    "dataset = dataset.drop(columns=date_columns, axis=1)\n",
    "dataset_test = dataset_test.drop(columns=date_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Org_Crop'] = dataset['OrgFertilizers'].astype(str) + \" + \" + dataset['CropbasalFerts'].astype(str)\n",
    "dataset_test['Org_Crop'] = dataset_test['OrgFertilizers'].astype(str) + \"+\" + dataset_test['CropbasalFerts'].astype(str)\n",
    "dataset['Crop_FirstTop'] = dataset['CropbasalFerts'].astype(str) + \"+\" + dataset['FirstTopDressFert'].astype(str)\n",
    "dataset_test['Crop_FirstTop'] = dataset_test['CropbasalFerts'].astype(str) + \"+\" + dataset_test['FirstTopDressFert'].astype(str)\n",
    "dataset['Org_FirstTop'] = dataset['OrgFertilizers'].astype(str) + \"+\" + dataset['FirstTopDressFert'].astype(str)\n",
    "dataset_test['Org_FirstTop'] = dataset_test['OrgFertilizers'].astype(str) + \"+\" + dataset_test['FirstTopDressFert'].astype(str)\n",
    "dataset['PCropSolidOrgFertAppMethod'] = dataset['PCropSolidOrgFertAppMethod'].fillna('other')\n",
    "dataset_test['PCropSolidOrgFertAppMethod'] = dataset_test['PCropSolidOrgFertAppMethod'].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all those new columns\n",
    "dataset = dataset.drop(columns=['Org_Crop', 'Crop_FirstTop', 'Org_FirstTop', 'PCropSolidOrgFertAppMethod'], axis=1)\n",
    "dataset_test = dataset_test.drop(columns=['Org_Crop', 'Crop_FirstTop', 'Org_FirstTop', 'PCropSolidOrgFertAppMethod'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dataset.columns:\n",
    "    if dataset[col].dtype == 'object':\n",
    "        dataset[col] = dataset[col].astype('category').cat.codes\n",
    "\n",
    "for col in dataset_test.columns:\n",
    "    if dataset_test[col].dtype == 'object':\n",
    "        dataset_test[col] = dataset_test[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset\n",
    "y = train_labels    \n",
    "\n",
    "# Train Test split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=200)\n",
    "\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Select the object columns and categorical columns\n",
    "object_cols = X.select_dtypes(include=['object'])\n",
    "categorical_cols = X.select_dtypes(include=['category'])\n",
    "whole_categorical_cols = pd.concat([object_cols, categorical_cols], axis=1) \n",
    "# generate a list with the name of the categorical columns\n",
    "whole_categorical_cols = whole_categorical_cols.columns\n",
    "# Transfer into a list\n",
    "whole_categorical_cols = list(whole_categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1233\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 597.052541\n",
      "Fold 0: RMSE: 412.15138447901995\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 593.591444\n",
      "Fold 1: RMSE: 410.4462386934124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 594.002297\n",
      "Fold 2: RMSE: 700.9901485402484\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 596.784668\n",
      "Fold 3: RMSE: 275.9341629826718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 595.194086\n",
      "Fold 4: RMSE: 354.45291815651706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1232\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 590.480907\n",
      "Fold 5: RMSE: 614.6758961647666\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1227\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 588.620729\n",
      "Fold 6: RMSE: 917.5337216583911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1227\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 594.782946\n",
      "Fold 7: RMSE: 274.75368722905216\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 598.389320\n",
      "Fold 8: RMSE: 209.33054196470653\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 593.793569\n",
      "Fold 9: RMSE: 400.00350391330886\n",
      "Mean RMSE: 457.0272203782095\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=100)\n",
    "\n",
    "# Prepare an array to store the RMSE for each fold\n",
    "rmse_scores = []\n",
    "models = []\n",
    "\n",
    "# Initialize an empty array to hold feature importances\n",
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "# Start the K-Fold cross-validation loop\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Create a LGBMRegressor object\n",
    "    lgbm_model = lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.01, n_estimators=100)\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train_fold, y_train_fold, \n",
    "        eval_set=[(X_val_fold, y_val_fold)], \n",
    "        eval_metric='mae', \n",
    "        categorical_feature=whole_categorical_cols\n",
    "    )\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = lgbm_model.predict(X_val_fold, num_iteration=0)\n",
    "\n",
    "    # Calculate and print RMSE for the current fold\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred_val))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold}: RMSE: {fold_rmse}\")\n",
    "\n",
    "    # Accumulate feature importances\n",
    "    feature_importances += lgbm_model.feature_importances_\n",
    "\n",
    "    models.append(lgbm_model)\n",
    "\n",
    "# After cross-validation, print the mean RMSE\n",
    "print(f\"Mean RMSE: {np.mean(rmse_scores)}\")\n",
    "\n",
    "# Feature importances from all folds\n",
    "feature_importances = feature_importances / n_splits\n",
    "# print(feature_importances)\n",
    "\n",
    "# Create a dataframe of feature importances\n",
    "# feature_importances_df = pd.DataFrame({'feature': list(X_train.columns), 'importance': feature_importances}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Print the top 20 features with their importance values\n",
    "# print(feature_importances_df.head(20))\n",
    "test_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    # Make predictions\n",
    "    fold_preds = model.predict(dataset_test, num_iteration=model.best_iteration_)\n",
    "    test_predictions.append(fold_preds)\n",
    "\n",
    "# Average these predictions\n",
    "test_predictions = np.column_stack(test_predictions)\n",
    "y_pred_test = np.mean(test_predictions, axis=1)\n",
    "\n",
    "submission_df = pd.DataFrame({'ID': ID, 'Yield': y_pred_test})\n",
    "submission_df.to_csv('result_file/submission_11_22_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(dataset_test.columns) - set(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new wandb run\n",
    "wandb.init(project='zindi-crop-challenge', \n",
    "           entity=\"lmu-seminar\")\n",
    "\n",
    "# Define your hyperparameters\n",
    "hyperparameters = dict(\n",
    "    objective='regression',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.009,\n",
    "    n_estimators=120,\n",
    "    # Add other hyperparameters you want to track here\n",
    ")\n",
    "\n",
    "# Save hyperparameters to wandb\n",
    "wandb.config.update(hyperparameters)\n",
    "\n",
    "# Rest of your code for preparing the data\n",
    "# ...\n",
    "\n",
    "# Parameters for cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=82)\n",
    "\n",
    "rmse_scores = []\n",
    "models = []\n",
    "\n",
    "feature_importances = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Start the K-Fold cross-validation loop\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Create a LGBMRegressor object with hyperparameters from wandb\n",
    "    lgbm_model = lgb.LGBMRegressor(**wandb.config)\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train_fold, y_train_fold, \n",
    "        eval_set=[(X_val_fold, y_val_fold)], \n",
    "        eval_metric='mae', \n",
    "        categorical_feature=whole_categorical_cols,\n",
    "        callbacks=[wandb.callback()]\n",
    "    )\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = lgbm_model.predict(X_val_fold, num_iteration=lgbm_model.best_iteration_)\n",
    "\n",
    "    # Calculate RMSE and log the metric to wandb\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred_val))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    wandb.log({'fold_rmse': fold_rmse, 'fold': fold})\n",
    "\n",
    "    # Feature importances\n",
    "    feature_importances += lgbm_model.feature_importances_\n",
    "\n",
    "    # Save the model to wandb\n",
    "    wandb.sklearn.log_model(lgbm_model, 'LGBMRegressor')\n",
    "    \n",
    "    models.append(lgbm_model)\n",
    "\n",
    "# Log mean and standard deviation of RMSE across folds to wandb\n",
    "wandb.log({'mean_rmse': np.mean(rmse_scores), 'std_rmse': np.std(rmse_scores)})\n",
    "\n",
    "# Feature importances\n",
    "feature_importances = feature_importances / n_splits\n",
    "# You can also log feature importances to wandb here\n",
    "\n",
    "# Finalize and close your wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

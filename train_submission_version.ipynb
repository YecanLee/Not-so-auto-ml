{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# Use ensemble to train the model\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import sys\n",
    "\n",
    "# In the second part of the notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# This part of importing would be moved to main.py or train.py later\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_option():\n",
    "    parse = argparse.ArgumentParser(\"Zindi Competition\", add_help=False)\n",
    "    parse.add_argument('--num_leaves', type=int, help=\"number of leaves in the tree model\", default=31)\n",
    "    parse.add_argument('--max_depth', type=int, help=\"maximum depth of the tree model\", default=-1)\n",
    "    parse.add_argument('--learning_rate', type=float, help=\"learning rate of the tree model\", default=0.1)\n",
    "    parse.add_argument('--n_estimators', type=int, help=\"number of trees in the tree model\", default=100)\n",
    "    parse.add_argument('--min_child_weight', type=float, help=\"minimum sum of instance weight (hessian) needed in a child (leaf)\", default=1e-3)\n",
    "    parse.add_argument('--subsample', type=float, help=\"subsample ratio of the training instance\", default=1.0)\n",
    "    parse.add_argument('--colsample_bytree', type=float, help=\"subsample ratio of columns when constructing each tree\", default=1.0)\n",
    "    parse.add_argument('--reg_alpha', type=float, help=\"L1 regularization term on weights\", default=0.0)\n",
    "    parse.add_argument('--reg_lambda', type=float, help=\"L2 regularization term on weights\", default=0.0)\n",
    "    parse.add_argument('--min_split_gain', type=float, help=\"minimum loss reduction required to make a further partition on a leaf node of the tree\", default=0.0)\n",
    "    parse.add_argument('--min_child_samples', type=int, help=\"minimum number of data needed in a child (leaf)\", default=20)\n",
    "    parse.add_argument('--num_iterations', type=int, help=\"number of boosting iterations\", default=100)\n",
    "    parse.add_argument('--early_stopping_round', type=int, help=\"number of rounds without improvements before stopping\", default=10)\n",
    "    parse.add_argument('--seed', type=int, help=\"seed for training\", default=42)\n",
    "    parse.add_argument('--verbose', type=int, help=\"verbose\", default=1)\n",
    "    parse.add_argument('--device', type=str, help=\"device to use for training\", default='cpu')\n",
    "    parse.add_argument('--num_folds', type=int, help=\"number of folds for cross validation\", default=5)\n",
    "    parse.add_argument('--wandb', action='store_true', help=\"log to wandb\")\n",
    "    parse.add_argument('--wandb_project', type=str, help=\"wandb project name\")\n",
    "    parse.add_argument('--wandb_entity', type=str, help=\"wandb entity name\")\n",
    "    parse.add_argument('--wandb_run_name', type=str, help=\"wandb run name\")\n",
    "    parse.add_argument('--wandb_tags', type=str, help=\"wandb tags\")\n",
    "    parse.add_argument('--wandb_group', type=str, help=\"wandb group\")\n",
    "    parse.add_argument('--wandb_job_type', type=str, help=\"wandb job type\")\n",
    "    parse.add_argument('--wandb_config', type=str, help=\"wandb config\")\n",
    "    parse.add_argument('--wandb_dir', type=str, help=\"wandb directory\")\n",
    "    parse.add_argument('--wandb_save_model', action='store_true', help=\"save model to wandb\")\n",
    "    parse.add_argument('--wandb_save_model_path', type=str, help=\"wandb save model path\")\n",
    "    parse.add_argument('--wandb_save_model_name', type=str, help=\"wandb save model name\")\n",
    "    parse.add_argument('--wandb_save_model_method', type=str, help=\"wandb save model method\")\n",
    "    parse.add_argument('--wandb_save_model_policy', type=str, help=\"wandb save model policy\")\n",
    "    parse.add_argument('--wandb_save_model_framework', type=str, help=\"wandb save model framework\")\n",
    "    parse.add_argument('--wandb_save_model_training_data', type=str, help=\"wandb save model training data\")\n",
    "    parse.add_argument('--wandb_save_model_validation_data', type=str, help=\"wandb save model validation data\")\n",
    "    parse.add_argument('--wandb_save_model_labels', type=str, help=\"wandb save model labels\")\n",
    "    parse.add_argument('--wandb_save_model_predictions', type=str, help=\"wandb save model predictions\")\n",
    "    parse.add_argument('--wandb_save_model_metric', type=str, help=\"wandb save model metric\")\n",
    "    parse.add_argument('--wandb_save_model_metric_value', type=float, help=\"wandb save model metric value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a hyperparameter class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.objective = 'regression'\n",
    "        self.num_leaves = 31\n",
    "        self.learning_rate = 0.01\n",
    "        self.n_estimators = 120\n",
    "        self.max_bin = 255\n",
    "        self.bagging_fraction = 0.8\n",
    "        self.bagging_freq = 5\n",
    "        self.feature_fraction = 0.8\n",
    "        self.feature_fraction_seed = 9\n",
    "        self.bagging_seed = 9\n",
    "        self.random_state = 42\n",
    "        self.OrgFertilizers = 'None'\n",
    "        self.FirstTopDressFert = 'None' \n",
    "        self.CropbasalFerts = 'None'\n",
    "        self.NursDetFactor = 'None'\n",
    "        self.LandPreparationMethod = 'None'\n",
    "        self.TransDetFactor = 'None'\n",
    "        self.PCropSolidOrgFertAppMethod = 'None'\n",
    "        self.sparse_threshold = 1.0\n",
    "# Instantiate the Hyperparameters class\n",
    "config = Config()\n",
    "\n",
    "# Initialize a wandb run\n",
    "wandb.init(project='zindi-crop-challenge',\n",
    "           entity=\"lmu-seminar\")\n",
    "\n",
    "# Update the wandb configuration with the hyperparameters\n",
    "wandb.config.update(vars(config))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset, remove the ID column and get the labels\n",
    "path = 'Train.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "train_labels = dataset['Yield'].copy()\n",
    "dataset = dataset.drop(columns=['ID','Yield'], axis=1)\n",
    "dataset_copy = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_path = 'Test.csv'\n",
    "dataset_test = pd.read_csv(test_path)\n",
    "test_labels = dataset_test['Yield'].copy()\n",
    "dataset_test = dataset_test.drop(columns=['ID', 'Yield'], axis=1)\n",
    "dataset_test_copy = dataset_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start with some very simple EDA analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the EDA steps have been commented out, please uncomment them to check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the missing data with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step would be checking the missing data inside the datasets\n",
    "\n",
    "# print(dataset.info())\n",
    "# print(dataset_test.info())\n",
    "\n",
    "# There are many missing data distributed in different data columns, thus we need to fill the missing data by trying different method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data type with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns, remember that object data includes object and category two dtypes\n",
    "numerical_cols = dataset.select_dtypes(include=['number']).columns\n",
    "categorical_cols = dataset.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vanilla model would be created for testing if the model needs a very complicated method to deal with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first explore whether a simple method would return us a good enough result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for numerical columns with median, then run a basic experiment, to show that there is no bug inside this right now\n",
    "for col in numerical_cols:\n",
    "    median_value = dataset_copy[col].median()\n",
    "    dataset_copy[col] = dataset_copy[col].fillna(median_value)\n",
    "    if col in dataset_test_copy.columns:\n",
    "        median_value_test = dataset_test_copy[col].median()\n",
    "        dataset_test_copy[col] = dataset_test_copy[col].fillna(median_value_test)  # Apply the same median value to the test set\n",
    "\n",
    "# Fill missing values for categorical columns with mode\n",
    "# Fill missing values for categorical columns with the mode\n",
    "for col in categorical_cols:\n",
    "    mode_value = dataset_copy[col].mode()[0]\n",
    "    dataset_copy[col] = dataset_copy[col].fillna(mode_value)\n",
    "    if col in dataset_test_copy.columns:\n",
    "        mode_value_test = dataset_test_copy[col].mode()[0]\n",
    "        dataset_test_copy[col] = dataset_test_copy[col].fillna(mode_value_test)  # Apply the same mode value to the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple lightgbm model test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for lightgbm model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the object datatype into \n",
    "for col in dataset_copy.columns:\n",
    "    if dataset_copy[col].dtype == 'object':\n",
    "        dataset_copy[col] = dataset_copy[col].astype('category').cat.codes\n",
    "    elif dataset_copy[col].dtype == 'datetime64[ns]':\n",
    "        dataset_copy = dataset_copy.drop(columns=[col])\n",
    "\n",
    "for col in dataset_test_copy.columns:\n",
    "    if dataset_test_copy[col].dtype == 'object':\n",
    "        dataset_test_copy[col] = dataset_test_copy[col].astype('category').cat.codes\n",
    "    elif dataset_test_copy[col].dtype == 'datetime64[ns]':\n",
    "        dataset_test_copy = dataset_test_copy.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the training hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_copy\n",
    "y = train_labels \n",
    "\n",
    "# The following line is need for the hyperparemeter 'categorical_feature' in the LGBMRegressor\n",
    "categorical_cols = list(categorical_cols)\n",
    "# print(categorical_cols)\n",
    "\n",
    "# Parameters\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Criterion List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = np.zeros(X.shape[1])\n",
    "# Prepare an array to store the RMSE for each fold\n",
    "rmse_scores = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the K-Fold cross-validation loop\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Create a LGBMRegressor object\n",
    "    lgbm_model = lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.1, n_estimators=42)\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train_fold, y_train_fold,  \n",
    "        eval_set=[(X_val_fold, y_val_fold)],\n",
    "        eval_metric='mse', \n",
    "        categorical_feature=categorical_cols\n",
    "    )\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = lgbm_model.predict(X_val_fold, num_iteration=lgbm_model.best_iteration_)\n",
    "\n",
    "    # Calculate and print RMSE for the current fold\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred_val))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold}: RMSE: {fold_rmse}\")\n",
    "\n",
    "    # Accumulate feature importances\n",
    "    feature_importances += lgbm_model.feature_importances_\n",
    "\n",
    "    models.append(lgbm_model)\n",
    "\n",
    "# After cross-validation, print the mean RMSE\n",
    "print(f\"Mean RMSE: {np.mean(rmse_scores)}\")\n",
    "\n",
    "# Feature importances from all folds\n",
    "feature_importances = feature_importances / n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    # Make predictions\n",
    "    test_df = dataset_test_copy[X.columns]\n",
    "    # print(test_df.shape)\n",
    "    fold_preds = model.predict(test_df, num_iteration=model.best_iteration_)\n",
    "    test_predictions.append(fold_preds)\n",
    "\n",
    "# Now average these predictions\n",
    "test_predictions = np.column_stack(test_predictions)\n",
    "y_pred_test = np.mean(test_predictions, axis=1)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_labels, y_pred_test))\n",
    "print(f\"MSE of the prediction is {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--- Great! We got our first result already! But can we improve this result? ---###\n",
    "\n",
    "# Should we deal with different missing values with different method? \n",
    "# The idea for dealing with different missing values would be checking the description of those variables first\n",
    "# We will first check the variable groups with variables related to Irrigation, a.k.a watering conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed EDA to explore the best way for filling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform column into 'Missing'/'Non-Missing'\n",
    "def missing_status(column):\n",
    "    return column.isna().map({True: 'Missing', False: 'Non-Missing'})\n",
    "\n",
    "# Plot setup\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# TransplantingIrrigationHours\n",
    "plt.subplot(1, 3, 1)  # Adjust for 3 subplots\n",
    "sns.countplot(y=missing_status(dataset['TransplantingIrrigationHours']))\n",
    "plt.title('TransplantingIrrigationHours Missing Status')\n",
    "\n",
    "# TransplantingIrrigationSource\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.countplot(y=missing_status(dataset['TransplantingIrrigationSource']))\n",
    "plt.title('TransplantingIrrigationSource Missing Status')\n",
    "\n",
    "# TransplantingIrrigationPowerSource\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(y=missing_status(dataset['TransplantingIrrigationPowerSource']))\n",
    "plt.title('TransplantingIrrigationPowerSource Missing Status')\n",
    "\n",
    "# Adjustments\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Separate plot for TransIrriCost\n",
    "plt.figure(figsize=(6, 4))  # Adjust the figure size as needed\n",
    "sns.countplot(y=missing_status(dataset['TransIrriCost']))\n",
    "plt.title('TransIrriCost Missing Status')\n",
    "\n",
    "# Adjustments\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data = dataset, y = dataset['TransplantingIrrigationHours'].fillna('nan'))\n",
    "plt.title('Distribution of TransplantingIrrigationHours')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(data = dataset, y = dataset['TransplantingIrrigationSource'].fillna('nan'))\n",
    "plt.title('Distribution of TransplantingIrrigationSource')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "sns.countplot(data = dataset, y = dataset['TransplantingIrrigationPowerSource'].fillna('nan'))\n",
    "plt.title('Distribution of TransplantingIrrigationPowerSource')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "sns.countplot(data = dataset.fillna(False), y = dataset['TransIrriCost'].fillna('NaN'))\n",
    "plt.title('Distribution of TransIrriCost')\n",
    "\n",
    "plt.xticks(size=5)\n",
    "plt.yticks(size=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big and boring code chunk to deal with the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset to include rows where 'TransplantingIrrigationHours' is not zero\n",
    "\n",
    "df_non_zero_irrigation = dataset[dataset['TransplantingIrrigationHours'] != 0]\n",
    "df_test_non_zero_irrigation = dataset_test[dataset_test['TransplantingIrrigationHours'] != 0]\n",
    "\n",
    "# Checking how many unique combinations exist for 'TransplantingIrrigationSource' and 'TransplantingIrrigationPowerSource'\n",
    "unique_combinations = df_non_zero_irrigation.groupby(['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource']).size().reset_index(name='Count')\n",
    "unique_combinations_test = df_test_non_zero_irrigation.groupby(['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource']).size().reset_index(name='Count')\n",
    "unique_combinations_count = unique_combinations.shape[0]\n",
    "unique_combinations_count_test = unique_combinations_test.shape[0]\n",
    "\n",
    "# Calculating the average 'TransIrriCost' for each group\n",
    "avg_cost_by_group = df_non_zero_irrigation.groupby(['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'])['TransIrriCost'].mean().reset_index()\n",
    "avg_cost_by_group_test = df_test_non_zero_irrigation.groupby(['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'])['TransIrriCost'].mean().reset_index()\n",
    "\n",
    "# Merging the average cost back to the original dataframe to fill missing values\n",
    "# We will perform a left join on the original dataframe with the average cost dataframe based on the two groupby columns\n",
    "dataset = dataset.merge(avg_cost_by_group, how='left', on=['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'], suffixes=('', '_avg'))\n",
    "dataset_test = dataset_test.merge(avg_cost_by_group_test, how='left', on=['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'], suffixes=('', '_avg'))\n",
    "\n",
    "# Now we fill the missing 'TransIrriCost' values where 'TransplantingIrrigationHours' is not zero\n",
    "# with the corresponding average cost from the same group\n",
    "mask = (dataset['TransplantingIrrigationHours'] != 0) & (dataset['TransIrriCost'].isnull())\n",
    "dataset.loc[mask, 'TransIrriCost'] = dataset.loc[mask, 'TransIrriCost_avg']\n",
    "mask_test = (dataset_test['TransplantingIrrigationHours'] != 0) & (dataset_test['TransIrriCost'].isnull())\n",
    "dataset_test.loc[mask_test, 'TransIrriCost'] = dataset_test.loc[mask_test, 'TransIrriCost_avg']\n",
    "\n",
    "dataset.drop('TransIrriCost_avg', axis=1, inplace=True)\n",
    "dataset_test.drop('TransIrriCost_avg', axis=1, inplace=True)\n",
    "\n",
    "# Filling in 'TransIrriCost' with 0 where 'TransplantingIrrigationHours' is 0\n",
    "dataset.loc[dataset['TransplantingIrrigationHours'] == 0, 'TransIrriCost'] = 0\n",
    "dataset_test.loc[dataset_test['TransplantingIrrigationHours'] == 0, 'TransIrriCost'] = 0\n",
    "\n",
    "# Find the mode of 'TransplantingIrrigationSource' for each 'CropEstMethod'\n",
    "irrigation_source_mode = dataset.groupby('CropEstMethod')['TransplantingIrrigationSource'].agg(pd.Series.mode).reset_index()\n",
    "irrigation_test_source_mode = dataset_test.groupby('CropEstMethod')['TransplantingIrrigationSource'].agg(pd.Series.mode).reset_index()\n",
    "\n",
    "# There can be more than one mode in a set of values, so we ensure to have a single value by picking the first one\n",
    "irrigation_source_mode['TransplantingIrrigationSource'] = irrigation_source_mode['TransplantingIrrigationSource'].apply(lambda x: x[0] if isinstance(x, (list, tuple)) else x)\n",
    "irrigation_test_source_mode['TransplantingIrrigationSource'] = irrigation_test_source_mode['TransplantingIrrigationSource'].apply(lambda x: x[0] if isinstance(x, (list, tuple)) else x)\n",
    "\n",
    "# Create a dictionary for mapping 'CropEstMethod' to the mode of 'TransplantingIrrigationSource'\n",
    "irrigation_source_map = dict(zip(irrigation_source_mode['CropEstMethod'], irrigation_source_mode['TransplantingIrrigationSource']))\n",
    "irrigation_test_source_map = dict(zip(irrigation_test_source_mode['CropEstMethod'], irrigation_test_source_mode['TransplantingIrrigationSource']))\n",
    "\n",
    "# Fill missing 'TransplantingIrrigationSource' values based on the 'CropEstMethod' they correspond to\n",
    "dataset['TransplantingIrrigationSource'] = dataset.apply(\n",
    "    lambda row: irrigation_source_map[row['CropEstMethod']] if pd.isnull(row['TransplantingIrrigationSource']) else row['TransplantingIrrigationSource'],\n",
    "    axis=1\n",
    ")\n",
    "dataset_test['TransplantingIrrigationSource'] = dataset_test.apply(\n",
    "    lambda row: irrigation_test_source_map[row['CropEstMethod']] if pd.isnull(row['TransplantingIrrigationSource']) else row['TransplantingIrrigationSource'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Next, we fill in the missing values for 'TransplantingIrrigationPowerSource' in a similar fashion\n",
    "power_source_mode = dataset.groupby('CropEstMethod')['TransplantingIrrigationPowerSource'].agg(pd.Series.mode).reset_index()\n",
    "power_source_test_mode = dataset_test.groupby('CropEstMethod')['TransplantingIrrigationPowerSource'].agg(pd.Series.mode).reset_index()\n",
    "power_source_mode['TransplantingIrrigationPowerSource'] = power_source_mode['TransplantingIrrigationPowerSource'].apply(lambda x: x[0] if isinstance(x, (list, tuple)) else x)\n",
    "power_source_map = dict(zip(power_source_mode['CropEstMethod'], power_source_mode['TransplantingIrrigationPowerSource']))\n",
    "dataset['TransplantingIrrigationPowerSource'] = dataset.apply(\n",
    "    lambda row: power_source_map[row['CropEstMethod']] if pd.isnull(row['TransplantingIrrigationPowerSource']) else row['TransplantingIrrigationPowerSource'],\n",
    "    axis=1\n",
    ")\n",
    "power_source_test_mode['TransplantingIrrigationPowerSource'] = power_source_test_mode['TransplantingIrrigationPowerSource'].apply(lambda x: x[0] if isinstance(x, (list, tuple)) else x)\n",
    "power_source_test_map = dict(zip(power_source_test_mode['CropEstMethod'], power_source_test_mode['TransplantingIrrigationPowerSource']))\n",
    "dataset_test['TransplantingIrrigationPowerSource'] = dataset_test.apply(\n",
    "    lambda row: power_source_test_map[row['CropEstMethod']] if pd.isnull(row['TransplantingIrrigationPowerSource']) else row['TransplantingIrrigationPowerSource'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Now, we recalculate the average 'TransIrriCost' for each group of 'TransplantingIrrigationSource' and 'TransplantingIrrigationPowerSource'\n",
    "avg_cost_by_group = dataset.groupby(['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'])['TransIrriCost'].mean().reset_index()\n",
    "dataset = dataset.merge(avg_cost_by_group, how='left', on=['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'], suffixes=('', '_avg'))\n",
    "avr_cost_by_group_test = dataset_test.groupby(['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'])['TransIrriCost'].mean().reset_index()\n",
    "dataset_test = dataset_test.merge(avr_cost_by_group_test, how='left', on=['TransplantingIrrigationSource', 'TransplantingIrrigationPowerSource'], suffixes=('', '_avg'))\n",
    "\n",
    "# Fill the missing 'TransIrriCost' values again\n",
    "mask = (dataset['TransplantingIrrigationHours'] != 0) & (dataset['TransIrriCost'].isnull())\n",
    "dataset.loc[mask, 'TransIrriCost'] = dataset.loc[mask, 'TransIrriCost_avg']\n",
    "dataset.drop('TransIrriCost_avg', axis=1, inplace=True)\n",
    "mask_test = (dataset_test['TransplantingIrrigationHours'] != 0) & (dataset_test['TransIrriCost'].isnull())\n",
    "dataset_test.loc[mask_test, 'TransIrriCost'] = dataset_test.loc[mask_test, 'TransIrriCost_avg']\n",
    "dataset_test.drop('TransIrriCost_avg', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the result after the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result after we do the preprocessing \n",
    "# Plot setup\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# TransplantingIrrigationHours\n",
    "plt.subplot(1, 3, 1)  # Adjust for 3 subplots\n",
    "sns.countplot(y=missing_status(dataset['TransplantingIrrigationHours']))\n",
    "plt.title('TransplantingIrrigationHours Missing Status')\n",
    "\n",
    "# TransplantingIrrigationSource\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.countplot(y=missing_status(dataset['TransplantingIrrigationSource']))\n",
    "plt.title('TransplantingIrrigationSource Missing Status')\n",
    "\n",
    "# TransplantingIrrigationPowerSource\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(y=missing_status(dataset['TransplantingIrrigationPowerSource']))\n",
    "plt.title('TransplantingIrrigationPowerSource Missing Status')\n",
    "\n",
    "# Adjustments\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Separate plot for TransIrriCost\n",
    "plt.figure(figsize=(6, 4))  # Adjust the figure size as needed\n",
    "sns.countplot(y=missing_status(dataset['TransIrriCost']))\n",
    "plt.title('TransIrriCost Missing Status')\n",
    "\n",
    "# Adjustments\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'Yield' column and drop it\n",
    "# Load the test dataset\n",
    "path = 'Train.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "train_labels = dataset['Yield'].copy()\n",
    "dataset = dataset.drop(columns=['ID','Yield'], axis = 1)\n",
    "ID = dataset_test['ID'].copy()\n",
    "dataset_test = dataset_test.drop(columns=['ID'], axis = 1)\n",
    "\n",
    "# Load the test dataset\n",
    "test_path = 'Test.csv'\n",
    "dataset_test = pd.read_csv(test_path)\n",
    "dataset_upload = dataset_test.copy()\n",
    "dataset_test = dataset_test.drop(columns=['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "path = 'Train.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "train_labels = dataset['Yield'].copy()\n",
    "dataset = dataset.drop(columns=['ID','Yield'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Harv_hand_rent'] = dataset['Harv_hand_rent'].fillna(0)\n",
    "dataset['OrgFertilizers'] = dataset['OrgFertilizers'].fillna(dataset['OrgFertilizers'].mode()[0])\n",
    "dataset['CropbasalFerts'] = dataset['CropbasalFerts'].fillna(dataset['CropbasalFerts'].mode()[0])\n",
    "dataset['FirstTopDressFert'] = dataset['FirstTopDressFert'].fillna(dataset['FirstTopDressFert'].mode()[0])\n",
    "dataset['NursDetFactor'] = dataset['NursDetFactor'].fillna(dataset['NursDetFactor'].mode()[0])\n",
    "dataset['LandPreparationMethod'] = dataset['LandPreparationMethod'].fillna(dataset['LandPreparationMethod'].mode()[0])\n",
    "dataset['TransDetFactor'] = dataset['TransDetFactor'].fillna(dataset['TransDetFactor'].mode()[0])\n",
    "dataset['PCropSolidOrgFertAppMethod'] = dataset['PCropSolidOrgFertAppMethod'].fillna(dataset['PCropSolidOrgFertAppMethod'].mode()[0])\n",
    "\n",
    "dataset_test['Harv_hand_rent'] = dataset_test['Harv_hand_rent'].fillna(0)\n",
    "dataset_test['OrgFertilizers'] = dataset_test['OrgFertilizers'].fillna(dataset_test['OrgFertilizers'].mode()[0])\n",
    "dataset_test['CropbasalFerts'] = dataset_test['CropbasalFerts'].fillna(dataset_test['CropbasalFerts'].mode()[0])\n",
    "dataset_test['FirstTopDressFert'] = dataset_test['FirstTopDressFert'].fillna(dataset_test['FirstTopDressFert'].mode()[0])\n",
    "dataset_test['NursDetFactor'] = dataset_test['NursDetFactor'].fillna(dataset_test['NursDetFactor'].mode()[0])\n",
    "dataset_test['LandPreparationMethod'] = dataset_test['LandPreparationMethod'].fillna(dataset_test['LandPreparationMethod'].mode()[0])\n",
    "dataset_test['TransDetFactor'] = dataset_test['TransDetFactor'].fillna(dataset_test['TransDetFactor'].mode()[0])\n",
    "dataset_test['PCropSolidOrgFertAppMethod'] = dataset_test['PCropSolidOrgFertAppMethod'].fillna(dataset_test['PCropSolidOrgFertAppMethod'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values for categorical variables to identify sparse classes\n",
    "categorical_columns = dataset.select_dtypes(include=['object']).columns\n",
    "sparse_classes = {col: dataset[col].nunique() for col in categorical_columns if dataset[col].nunique() > 15} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['LandPreparationMethod', 'CropTillageDate', 'RcNursEstDate', 'SeedingSowingTransplanting', 'NursDetFactor', 'TransDetFactor', 'OrgFertilizers', 'CropbasalFerts', 'Harv_date', 'Threshing_date'])\n"
     ]
    }
   ],
   "source": [
    "# check the name of sparse classes\n",
    "print(sparse_classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([43, 78, 61, 62, 125, 155, 31, 34, 107, 162])\n"
     ]
    }
   ],
   "source": [
    "# check the unique values of sparse classes\n",
    "print(sparse_classes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for grouping\n",
    "threshold_percentage = 1\n",
    "threshold = len(dataset) * (threshold_percentage / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group sparse classes\n",
    "def group_sparse_classes(df, column, threshold):\n",
    "    # Find the categories that are below the threshold\n",
    "    value_counts = df[column].value_counts()\n",
    "    to_replace = value_counts[value_counts <= threshold].index.tolist()\n",
    "    \n",
    "    # Replace the sparse classes with 'other'\n",
    "    df[column] = df[column].replace(to_replace, 'other')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply grouping for the identified categorical variables with many unique values\n",
    "for col in ['LandPreparationMethod', 'OrgFertilizers', 'CropbasalFerts']:\n",
    "    dataset = group_sparse_classes(dataset, col, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the category adjustment to the test dataset based on the training dataset categories\n",
    "for col in ['LandPreparationMethod', 'OrgFertilizers', 'CropbasalFerts']:\n",
    "    test_dataset = group_sparse_classes(dataset_test, col, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 skewed numerical features to Box Cox transform\n",
      "CultLand                         8.178796\n",
      "CropCultLand                     8.796317\n",
      "SeedlingsPerPit                 53.528364\n",
      "TransplantingIrrigationHours    30.754264\n",
      "TransIrriCost                    3.912326\n",
      "StandingWater                    1.848641\n",
      "Ganaura                          5.237242\n",
      "CropOrgFYM                       6.876849\n",
      "BasalDAP                         2.905715\n",
      "BasalUrea                        2.244465\n",
      "1tdUrea                          2.094479\n",
      "1appDaysUrea                     4.769872\n",
      "2tdUrea                          2.696580\n",
      "2appDaysUrea                    -1.589283\n",
      "Harv_hand_rent                  40.547049\n",
      "Residue_length                  -1.880371\n",
      "Residue_perc                     3.747956\n",
      "Acre                             2.384037\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# fill the high skewness columns with median\n",
    "# check the skewness of the numerical columns\n",
    "skewness = dataset.skew(numeric_only=True)\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "# sort the skewness in descending order\n",
    "skewness.sort_values(ascending=False)\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_skewed_features = ['SeedlingsPerPit', 'TransplantingIrrigationHours','Harv_hand_rent']\n",
    "low_skewed_features = ['CultLand', 'CropOrgFYM', 'CropCultLand','Ganaura'] \n",
    "moderate_skewed_features = ['BasalUrea', 'BasalDAP',\n",
    "                            '1tdUrea', '1appDaysUrea', \n",
    "                            '2tdUrea', '2appDaysUrea',\n",
    "                            'Residue_length', 'Residue_perc',\n",
    "                            'StandingWater', 'TransIrriCost',\n",
    "                            'TransIrriCost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeedlingsPerPit                 float64\n",
      "TransplantingIrrigationHours    float64\n",
      "Harv_hand_rent                  float64\n",
      "dtype: object\n",
      "CultLand          int64\n",
      "CropOrgFYM      float64\n",
      "CropCultLand      int64\n",
      "Ganaura         float64\n",
      "dtype: object\n",
      "BasalUrea         float64\n",
      "BasalDAP          float64\n",
      "1tdUrea           float64\n",
      "1appDaysUrea      float64\n",
      "2tdUrea           float64\n",
      "2appDaysUrea      float64\n",
      "Residue_length      int64\n",
      "Residue_perc        int64\n",
      "StandingWater     float64\n",
      "TransIrriCost     float64\n",
      "TransIrriCost     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the dtype of those skewed features\n",
    "print(dataset[high_skewed_features].dtypes)\n",
    "print(dataset[low_skewed_features].dtypes)\n",
    "print(dataset[moderate_skewed_features].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the low skewness columns with mean\n",
    "for feat in low_skewed_features:\n",
    "    dataset[feat] = dataset[feat].fillna(dataset[feat].mean())\n",
    "    dataset_test[feat] = dataset_test[feat].fillna(dataset_test[feat].mean())\n",
    "\n",
    "# Fill the moderate skewness columns with median\n",
    "for feat in moderate_skewed_features:\n",
    "    dataset[feat] = dataset[feat].fillna(dataset[feat].median())\n",
    "    dataset_test[feat] = dataset_test[feat].fillna(dataset_test[feat].median())\n",
    "\n",
    "# Fill the high skewness columns with median\n",
    "for feat in high_skewed_features:\n",
    "    dataset[feat] = dataset[feat].fillna(dataset[feat].median())\n",
    "    dataset_test[feat] = dataset_test[feat].fillna(dataset_test[feat].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nskewed_features = skewness.index\\nlam = 0.15\\n# apply the boxcox1p transformation to the skewed features\\nfor feat in skewed_features:\\n    dataset[feat] = boxcox1p(dataset[feat], lam)\\n    dataset_test[feat] = boxcox1p(dataset_test[feat], lam)\\n\\n# check the skewness of the numerical columns\\nskewness = dataset.skew(numeric_only=True)\\nskewness = skewness[abs(skewness) > 0.5]\\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "# apply the boxcox1p transformation to the skewed features\n",
    "for feat in skewed_features:\n",
    "    dataset[feat] = boxcox1p(dataset[feat], lam)\n",
    "    dataset_test[feat] = boxcox1p(dataset_test[feat], lam)\n",
    "\n",
    "# check the skewness of the numerical columns\n",
    "skewness = dataset.skew(numeric_only=True)\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbins_SeedlingsPerPit = [0, 2, 4, np.inf]\\nlabels_SeedlingsPerPit = ['Low', 'Medium', 'High']\\ndataset['SeedlingsPerPit_Binned'] = pd.cut(dataset['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\\ndataset_test['SeedlingsPerPit_Binned'] = pd.cut(dataset_test['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bins_SeedlingsPerPit = [0, 2, 4, np.inf]\n",
    "labels_SeedlingsPerPit = ['Low', 'Medium', 'High']\n",
    "dataset['SeedlingsPerPit_Binned'] = pd.cut(dataset['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\n",
    "dataset_test['SeedlingsPerPit_Binned'] = pd.cut(dataset_test['SeedlingsPerPit'], bins=bins_SeedlingsPerPit, labels=labels_SeedlingsPerPit)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbins_NoFertilizerAppln = [0, 1, 2, np.inf]\\nlabels_NoFertilizerAppln = ['Low', 'Medium', 'High']\\ndataset['NoFertilizerAppln_Binned'] = pd.cut(dataset['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\\ndataset_test['NoFertilizerAppln_Binned'] = pd.cut(dataset_test['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bins_NoFertilizerAppln = [0, 1, 2, np.inf]\n",
    "labels_NoFertilizerAppln = ['Low', 'Medium', 'High']\n",
    "dataset['NoFertilizerAppln_Binned'] = pd.cut(dataset['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\n",
    "dataset_test['NoFertilizerAppln_Binned'] = pd.cut(dataset_test['NoFertilizerAppln'], bins=bins_NoFertilizerAppln, labels=labels_NoFertilizerAppln)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RcNursEstDate is NaN, then fill NursDetFactor with None\n",
    "# if RcNursEstDate is not NaN, then fill NursDetFactor with mode\n",
    "dataset.loc[dataset['RcNursEstDate'].isnull(), 'NursDetFactor'] = 'None'\n",
    "dataset.loc[dataset['RcNursEstDate'].notnull(), 'NursDetFactor'] = dataset['NursDetFactor'].mode()[0]\n",
    "\n",
    "dataset_test.loc[dataset_test['RcNursEstDate'].isnull(), 'NursDetFactor'] = 'None'\n",
    "dataset_test.loc[dataset_test['RcNursEstDate'].notnull(), 'NursDetFactor'] = dataset_test['NursDetFactor'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing value with MineralFertAppMethod.1 with mode\n",
    "dataset['MineralFertAppMethod.1'] = dataset['MineralFertAppMethod.1'].fillna(dataset['MineralFertAppMethod.1'].mode()[0])\n",
    "dataset_test['MineralFertAppMethod.1'] = dataset_test['MineralFertAppMethod.1'].fillna(dataset_test['MineralFertAppMethod.1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date columns\n",
    "date_columns = ['Harv_date', 'SeedingSowingTransplanting', 'RcNursEstDate', 'Threshing_date', 'CropTillageDate']\n",
    "\n",
    "# fill the missing values with mode\n",
    "for col in date_columns:\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].mode()[0])\n",
    "    dataset_test[col] = dataset_test[col].fillna(dataset_test[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date columns to datetime\n",
    "for col in date_columns:\n",
    "    dataset[col] = pd.to_datetime(dataset[col])\n",
    "    dataset_test[col] = pd.to_datetime(dataset_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Harv_date_RcNursEstDate'] = (dataset['Harv_date'] - dataset['RcNursEstDate']).dt.days\n",
    "dataset_test['Harv_date_RcNursEstDate'] = (dataset_test['Harv_date'] - dataset_test['RcNursEstDate']).dt.days\n",
    "dataset.loc[dataset['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] = dataset.loc[dataset['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] + 365\n",
    "dataset_test.loc[dataset_test['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] = dataset_test.loc[dataset_test['Harv_date_RcNursEstDate'] < 0, 'Harv_date_RcNursEstDate'] + 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harvest_date - CropTillageDate\n",
    "dataset['CropTillageDate'] = pd.to_datetime(dataset['CropTillageDate'])\n",
    "dataset_test['CropTillageDate'] = pd.to_datetime(dataset_test['CropTillageDate'])\n",
    "dataset['Harv_date_CropTillageDate'] = (dataset['Harv_date'] - dataset['CropTillageDate']).dt.days\n",
    "dataset_test['Harv_date_CropTillageDate'] = (dataset_test['Harv_date'] - dataset_test['CropTillageDate']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshing_date - Harvest_date\n",
    "dataset['Threshing_date'] = pd.to_datetime(dataset['Threshing_date'])\n",
    "dataset['Threshing_date_Harv_date'] = (dataset['Threshing_date'] - dataset['Harv_date']).dt.days\n",
    "dataset_test['Threshing_date'] = pd.to_datetime(dataset_test['Threshing_date'])\n",
    "dataset_test['Threshing_date_Harv_date'] = (dataset_test['Threshing_date'] - dataset_test['Harv_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the month features, this will be transfered into one-hot encoding later\n",
    "dataset['Harv_date_Month'] = dataset['Harv_date'].dt.month\n",
    "dataset_test['Harv_date_Month'] = dataset_test['Harv_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the month values to the season values\n",
    "month_to_season = {1: 1, 2: 1, 3: 1, 4: 2, 5: 2,\n",
    "                     6: 2, 7: 3, 8: 3, 9: 3, 10: 4,\n",
    "                     11: 4, 12: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the month values to the season values\n",
    "dataset['Harv_date_Season'] = dataset['Harv_date_Month'].map(month_to_season)\n",
    "dataset_test['Harv_date_Season'] = dataset_test['Harv_date_Month'].map(month_to_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Harv_date_Month'], axis=1)\n",
    "dataset_test = dataset_test.drop(columns=['Harv_date_Month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original date columns\n",
    "dataset = dataset.drop(columns=date_columns, axis=1)\n",
    "dataset_test = dataset_test.drop(columns=date_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Org_Crop'] = dataset['OrgFertilizers'].astype(str) + \" + \" + dataset['CropbasalFerts'].astype(str)\n",
    "dataset_test['Org_Crop'] = dataset_test['OrgFertilizers'].astype(str) + \"+\" + dataset_test['CropbasalFerts'].astype(str)\n",
    "dataset['Crop_FirstTop'] = dataset['CropbasalFerts'].astype(str) + \"+\" + dataset['FirstTopDressFert'].astype(str)\n",
    "dataset_test['Crop_FirstTop'] = dataset_test['CropbasalFerts'].astype(str) + \"+\" + dataset_test['FirstTopDressFert'].astype(str)\n",
    "dataset['Org_FirstTop'] = dataset['OrgFertilizers'].astype(str) + \"+\" + dataset['FirstTopDressFert'].astype(str)\n",
    "dataset_test['Org_FirstTop'] = dataset_test['OrgFertilizers'].astype(str) + \"+\" + dataset_test['FirstTopDressFert'].astype(str)\n",
    "dataset['PCropSolidOrgFertAppMethod'] = dataset['PCropSolidOrgFertAppMethod'].fillna('other')\n",
    "dataset_test['PCropSolidOrgFertAppMethod'] = dataset_test['PCropSolidOrgFertAppMethod'].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all those new columns\n",
    "dataset = dataset.drop(columns=['Org_Crop', 'Crop_FirstTop', 'Org_FirstTop', 'PCropSolidOrgFertAppMethod'], axis=1)\n",
    "dataset_test = dataset_test.drop(columns=['Org_Crop', 'Crop_FirstTop', 'Org_FirstTop', 'PCropSolidOrgFertAppMethod'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dataset.columns:\n",
    "    if dataset[col].dtype == 'object':\n",
    "        dataset[col] = dataset[col].astype('category').cat.codes\n",
    "\n",
    "for col in dataset_test.columns:\n",
    "    if dataset_test[col].dtype == 'object':\n",
    "        dataset_test[col] = dataset_test[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset\n",
    "y = train_labels    \n",
    "\n",
    "# Train Test split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=200)\n",
    "\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Select the object columns and categorical columns\n",
    "object_cols = X.select_dtypes(include=['object'])\n",
    "categorical_cols = X.select_dtypes(include=['category'])\n",
    "whole_categorical_cols = pd.concat([object_cols, categorical_cols], axis=1) \n",
    "# generate a list with the name of the categorical columns\n",
    "whole_categorical_cols = whole_categorical_cols.columns\n",
    "# Transfer into a list\n",
    "whole_categorical_cols = list(whole_categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1233\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 597.052541\n",
      "Fold 0: RMSE: 412.15138447901995\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 593.591444\n",
      "Fold 1: RMSE: 410.4462386934124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 594.002297\n",
      "Fold 2: RMSE: 700.9901485402484\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 596.784668\n",
      "Fold 3: RMSE: 275.9341629826718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 595.194086\n",
      "Fold 4: RMSE: 354.45291815651706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1232\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 590.480907\n",
      "Fold 5: RMSE: 614.6758961647666\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1227\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 588.620729\n",
      "Fold 6: RMSE: 917.5337216583911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1227\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 594.782946\n",
      "Fold 7: RMSE: 274.75368722905216\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 598.389320\n",
      "Fold 8: RMSE: 209.33054196470653\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 3483, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 593.793569\n",
      "Fold 9: RMSE: 400.00350391330886\n",
      "Mean RMSE: 457.0272203782095\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=100)\n",
    "\n",
    "# Prepare an array to store the RMSE for each fold\n",
    "rmse_scores = []\n",
    "models = []\n",
    "\n",
    "# Initialize an empty array to hold feature importances\n",
    "feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "# Start the K-Fold cross-validation loop\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Create a LGBMRegressor object\n",
    "    lgbm_model = lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.01, n_estimators=100)\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train_fold, y_train_fold, \n",
    "        eval_set=[(X_val_fold, y_val_fold)], \n",
    "        eval_metric='mae', \n",
    "        categorical_feature=whole_categorical_cols\n",
    "    )\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = lgbm_model.predict(X_val_fold, num_iteration=0)\n",
    "\n",
    "    # Calculate and print RMSE for the current fold\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred_val))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold}: RMSE: {fold_rmse}\")\n",
    "\n",
    "    # Accumulate feature importances\n",
    "    feature_importances += lgbm_model.feature_importances_\n",
    "\n",
    "    models.append(lgbm_model)\n",
    "\n",
    "# After cross-validation, print the mean RMSE\n",
    "print(f\"Mean RMSE: {np.mean(rmse_scores)}\")\n",
    "\n",
    "# Feature importances from all folds\n",
    "feature_importances = feature_importances / n_splits\n",
    "# print(feature_importances)\n",
    "\n",
    "# Create a dataframe of feature importances\n",
    "# feature_importances_df = pd.DataFrame({'feature': list(X_train.columns), 'importance': feature_importances}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Print the top 20 features with their importance values\n",
    "# print(feature_importances_df.head(20))\n",
    "test_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    # Make predictions\n",
    "    fold_preds = model.predict(dataset_test, num_iteration=model.best_iteration_)\n",
    "    test_predictions.append(fold_preds)\n",
    "\n",
    "# Average these predictions\n",
    "test_predictions = np.column_stack(test_predictions)\n",
    "y_pred_test = np.mean(test_predictions, axis=1)\n",
    "\n",
    "submission_df = pd.DataFrame({'ID': ID, 'Yield': y_pred_test})\n",
    "submission_df.to_csv('result_file/submission_11_22_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(dataset_test.columns) - set(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new wandb run\n",
    "wandb.init(project='zindi-crop-challenge', \n",
    "           entity=\"lmu-seminar\")\n",
    "\n",
    "# Define your hyperparameters\n",
    "hyperparameters = dict(\n",
    "    objective='regression',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.009,\n",
    "    n_estimators=120,\n",
    "    # Add other hyperparameters you want to track here\n",
    ")\n",
    "\n",
    "# Save hyperparameters to wandb\n",
    "wandb.config.update(hyperparameters)\n",
    "\n",
    "# Rest of your code for preparing the data\n",
    "# ...\n",
    "\n",
    "# Parameters for cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=82)\n",
    "\n",
    "rmse_scores = []\n",
    "models = []\n",
    "\n",
    "feature_importances = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Start the K-Fold cross-validation loop\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Create a LGBMRegressor object with hyperparameters from wandb\n",
    "    lgbm_model = lgb.LGBMRegressor(**wandb.config)\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train_fold, y_train_fold, \n",
    "        eval_set=[(X_val_fold, y_val_fold)], \n",
    "        eval_metric='mae', \n",
    "        categorical_feature=whole_categorical_cols,\n",
    "        callbacks=[wandb.callback()]\n",
    "    )\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = lgbm_model.predict(X_val_fold, num_iteration=lgbm_model.best_iteration_)\n",
    "\n",
    "    # Calculate RMSE and log the metric to wandb\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred_val))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    wandb.log({'fold_rmse': fold_rmse, 'fold': fold})\n",
    "\n",
    "    # Feature importances\n",
    "    feature_importances += lgbm_model.feature_importances_\n",
    "\n",
    "    # Save the model to wandb\n",
    "    wandb.sklearn.log_model(lgbm_model, 'LGBMRegressor')\n",
    "    \n",
    "    models.append(lgbm_model)\n",
    "\n",
    "# Log mean and standard deviation of RMSE across folds to wandb\n",
    "wandb.log({'mean_rmse': np.mean(rmse_scores), 'std_rmse': np.std(rmse_scores)})\n",
    "\n",
    "# Feature importances\n",
    "feature_importances = feature_importances / n_splits\n",
    "# You can also log feature importances to wandb here\n",
    "\n",
    "# Finalize and close your wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
